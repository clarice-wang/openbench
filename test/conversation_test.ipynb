{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import importlib\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "sys.path.append('../src/')\n",
    "import oracle\n",
    "import agent_a\n",
    "import agent_b\n",
    "import agent_c\n",
    "import prompts\n",
    "import conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'prompts' from '/Users/shiyimin/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Projects/llm_lead/interviews/test/../src/prompts.py'>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(conversation)\n",
    "importlib.reload(agent_a)\n",
    "importlib.reload(agent_b)\n",
    "importlib.reload(agent_c)\n",
    "importlib.reload(prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## job: data scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### slight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = \"../data/scripts/job/data_scientist_slight.json\"\n",
    "q_path = \"../data/questionnaires/data_scientist_slight_q.json\"\n",
    "config_path = \"../config/backbone/backbone_configs.json\"\n",
    "conv = conversation.make_conversation(s_path, q_path, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative conversation: 100%|████████████████████████████████████████████████████| 10/10 [00:56<00:00,  5.65s/it]\n"
     ]
    }
   ],
   "source": [
    "conv.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  10%|█████▌                                                  | 1/10 [00:02<00:26,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"During my final year at Wisconsin Madison, I worked on a project titled 'Predicting Financial Trends Using Machine Learning.' This project was part of the course COMP SCI 540 — Introduction to Artificial Intelligence.\"]\n",
      "reason: The retrieved relevant piece mentions that the interviewee worked on a project during their final year at Wisconsin Madison, but it does not specify the degree they were pursuing. Without explicit information about their degree, we cannot determine the correct option from the choices provided.\n",
      "answer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  20%|███████████▏                                            | 2/10 [00:05<00:23,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"While I have not had direct experience working with engineering teams to take prototypes to production in a professional capacity, my academic projects have given me a solid understanding of the processes involved.\",\n",
      "\"While I haven't had direct experience working with a large technology company in a formal machine learning or data scientist role, my academic projects have provided me with valuable team collaboration experience and opportunities to apply my skills in Python, TensorFlow, and PyTorch.\"]\n",
      "reason: The retrieved relevant pieces clearly state that the interviewee has not had direct professional experience in engineering or data scientist roles, indicating that they have no prior working experience.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  30%|████████████████▊                                       | 3/10 [00:09<00:22,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my project \\\"Predicting Financial Trends Using Machine Learning,\\\" I applied my statistical knowledge to enhance the reliability of model predictions.\",\n",
      "    \"In this project, I primarily focused on using Python libraries such as pandas and NumPy to perform statistical analysis, which included assessing model performance.\",\n",
      "    \"I'm confident that my foundation in statistics equips me to apply these measures in future projects to ensure the reliability of model predictions.\",\n",
      "    \"In my experience, Python has been an indispensable tool in my data science work, particularly through libraries like pandas and NumPy, which have enhanced my ability to perform complex data manipulation and analysis tasks efficiently.\"\n",
      "]\n",
      "reason: The retrieved pieces mention the interviewee's use of Python and libraries like pandas and NumPy for statistical analysis, but they do not mention the use of R or PyG, indicating that these might not be part of their skill set for statistics work.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  40%|██████████████████████▍                                 | 4/10 [00:12<00:19,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"During my final year at Wisconsin Madison, I worked on a project titled 'Predicting Financial Trends Using Machine Learning.'\",\n",
      "    \"I applied state-of-the-art models like NBEATS and NHITS within the NeuralForecast framework to predict the price trend of NVDA stock.\",\n",
      "    \"In the 'Predicting Financial Trends Using Machine Learning' project, I applied these skills to manage and preprocess the data, ensuring it was ready for model development.\",\n",
      "    \"In terms of time series modeling and machine learning forecasting applications, my most relevant experience comes from the project on 'Predicting Financial Trends Using Machine Learning.'\",\n",
      "    \"During the 'Predicting Financial Trends Using Machine Learning' project, I worked within a team environment, collaborating with classmates to develop models and streamline the data pipeline.\"\n",
      "]\n",
      "reason: The retrieved relevant pieces clearly indicate that the interviewee's main focus was on predicting financial trends using machine learning, specifically through a project that involved predicting NVDA stock price trends using advanced models.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  50%|████████████████████████████                            | 5/10 [00:15<00:15,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"Although I don't have experience with causal inference, my project involved integrating various exogenous variables like market trends and economic indicators, which enriched the model's insights and contributed to the robustness of the forecasting application.\",\n",
      "\"I have a basic background in statistics and am familiar with key concepts like probability distributions and statistical inference methods.\"]\n",
      "reason: The retrieved relevant pieces indicate that the interviewee does not have experience with causal inference but is familiar with statistical concepts, suggesting a basic understanding without practice.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  60%|█████████████████████████████████▌                      | 6/10 [00:19<00:13,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"In terms of time series modeling and machine learning forecasting applications, my most relevant experience comes from the project on 'Predicting Financial Trends Using Machine Learning.'\",\n",
      "\"I applied advanced time series models, specifically the NBEATS and NHITS models, to forecast the price trends of NVDA stock.\",\n",
      "\"These models are designed to capture complex patterns in time series data and were instrumental in achieving high accuracy in predictions.\",\n",
      "\"Overall, the project enhanced my understanding of the intricacies involved in time series forecasting using machine learning.\"]\n",
      "reason: The retrieved pieces indicate that the interviewee has practical experience with time series modeling through a specific project where they applied advanced models like NBEATS and NHITS to forecast stock price trends. This suggests a level of expertise beyond basic understanding, though not necessarily in-depth expertise across all areas of time series modeling.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  70%|███████████████████████████████████████▏                | 7/10 [00:23<00:10,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"I'm glad to share my experience in developing forecasting models.\",\n",
      "    \"During my final year at Wisconsin Madison, I worked on a project titled 'Predicting Financial Trends Using Machine Learning.'\",\n",
      "    \"I applied state-of-the-art models like NBEATS and NHITS within the NeuralForecast framework to predict the price trend of NVDA stock.\",\n",
      "    \"In the 'Predicting Financial Trends Using Machine Learning' project, I applied these skills to manage and preprocess the data, ensuring it was ready for model development.\",\n",
      "    \"To assess the models' effectiveness, I focused on the accuracy of the predictions.\",\n",
      "    \"In my project 'Predicting Financial Trends Using Machine Learning,' I applied my statistical knowledge to enhance the reliability of model predictions.\",\n",
      "    \"I've used Python extensively for data preprocessing, statistical analysis, and implementing machine learning models.\",\n",
      "    \"Additionally, I've worked with other libraries such as TensorFlow, PyTorch, and scikit-learn, which have allowed me to build and optimize deep learning models.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has significant experience with machine learning models, statistical analysis, data preprocessing, and the use of libraries like TensorFlow and PyTorch, which aligns closely with the responsibilities of a Data Scientist.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  80%|████████████████████████████████████████████▊           | 8/10 [00:27<00:07,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Although I wouldn't say I have extensive experience with modern batch processing or streaming systems like Spark or Flink, I've been involved in data cleansing and understanding ETL processes and data warehousing principles.\",\n",
      "    \"While I wouldn't consider myself an expert in all statistical measures, I have a basic background in statistics and am familiar with key concepts like probability distributions and statistical inference methods.\",\n",
      "    \"During my final year at Wisconsin Madison, I worked on a project titled 'Predicting Financial Trends Using Machine Learning.'\"\n",
      "]\n",
      "reason: The retrieved relevant pieces indicate that the interviewee lacks extensive experience with modern big data systems like Spark or Flink, while having a basic understanding of statistics and financial market prediction.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  90%|██████████████████████████████████████████████████▍     | 9/10 [00:31<00:03,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my experience with extracting data from large, complex datasets, I've primarily worked with relational database systems and used SQL for data extraction and manipulation.\",\n",
      "    \"Although I wouldn't say I have extensive experience with modern batch processing or streaming systems like Spark or Flink, I've been involved in data cleansing and understanding ETL processes and data warehousing principles.\",\n",
      "    \"While I haven't used other scripting languages like Perl extensively, my proficiency with Python has equipped me with the skills necessary to tackle a wide range of data science challenges, from statistical analysis to deploying machine learning models.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has some experience with relational database systems, data cleansing, ETL processes, and data warehousing, but not with big data technologies like Spark or Flink, suggesting a moderate willingness to discuss big data-related knowledge.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████| 10/10 [00:34<00:00,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"During the 'Predicting Financial Trends Using Machine Learning' project, I worked within a team environment, collaborating with classmates to develop models and streamline the data pipeline.\",\n",
      "    \"In this setting, we faced challenges in managing computational resources and optimizing model performance, which required effective teamwork and communication.\",\n",
      "    \"We overcame these challenges by dividing tasks based on individual strengths, ensuring efficient use of our collective skill sets.\",\n",
      "    \"Through these experiences, I've honed my ability to work collaboratively, leverage Python and machine learning frameworks, and tackle complex data science challenges.\"\n",
      "]\n",
      "reason: The retrieved pieces highlight the interviewee's collaborative nature, showcasing their teamwork and communication skills during a project where they worked effectively with classmates, divided tasks based on strengths, and honed their ability to tackle challenges collectively.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.5, 'answer_rate': 0.9}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.evaluate_performance(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = \"../data/scripts/job/data_scientist_normal.json\"\n",
    "q_path = \"../data/questionnaires/data_scientist_normal_q.json\"\n",
    "config_path = \"../config/backbone/backbone_configs.json\"\n",
    "conv2 = conversation.make_conversation(s_path, q_path, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative conversation: 100%|████████████████████████████████████████████████████| 10/10 [01:01<00:00,  6.16s/it]\n"
     ]
    }
   ],
   "source": [
    "conv2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  10%|█████▌                                                  | 1/10 [00:04<00:37,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"One of the key experiences I've had in developing forecasting models was during a final project for my COMP SCI 540 course, which focused on predicting financial trends using machine learning.\"]\n",
      "reason: The retrieved relevant piece indicates that the interviewee took a COMP SCI 540 course, which is typically a graduate-level course in computer science, suggesting they are likely pursuing or have completed a master's degree in computer science.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  20%|███████████▏                                            | 2/10 [00:07<00:31,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"While I haven't had the opportunity to work in a machine learning or data scientist role with a large technology company yet, my academic experiences have been instrumental in preparing me for such roles.\",\n",
      " \"Throughout my education, especially in projects like the financial trend prediction one, I have extensively used Python, which is a key language in data science.\"]\n",
      "reason: The retrieved relevant pieces indicate that the interviewee has not worked in a data scientist role with a large technology company and only mentions academic experience. Therefore, the most accurate choice reflecting the interviewee's professional experience is that they have no work experience.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  30%|████████████████▊                                       | 3/10 [00:15<00:38,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"I applied the NBEATS and NHITS models within NeuralForecast to predict the price trend of NVDA stock.\",\n",
      "    \"I used Python libraries such as pandas and NumPy for statistical inference, which streamlined the training, testing, and forecasting processes.\",\n",
      "    \"I used Python as my primary tool, leveraging libraries such as pandas and NumPy for data manipulation and statistical analysis.\",\n",
      "    \"We employed efficient data preprocessing techniques and leveraged Python libraries such as pandas and NumPy to handle data efficiently, which are essential steps before any model can be scaled or deployed.\",\n",
      "    \"My proficiency with statistical programming in Python also supported these efforts, allowing me to perform the necessary calculations and visualizations efficiently.\",\n",
      "    \"I implemented models like NBEATS and NHITS within NeuralForecast to predict the price trends of NVDA stock.\",\n",
      "    \"Throughout my education, especially in projects like the financial trend prediction one, I have extensively used Python, which is a key language in data science.\",\n",
      "    \"I leveraged Python's powerful libraries, such as TensorFlow, PyTorch, pandas, and NumPy, to streamline these processes and handle large datasets efficiently.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has used Python extensively for statistical programming, leveraging libraries such as pandas and NumPy. However, there is no mention of R or PyG in the retrieved information, implying they might not be part of the interviewee's skill set for statistics work.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  40%|██████████████████████▍                                 | 4/10 [00:19<00:30,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"One of the key experiences I've had in developing forecasting models was during a final project for my COMP SCI 540 course, which focused on predicting financial trends using machine learning.\",\n",
      "    \"I applied the NBEATS and NHITS models within NeuralForecast to predict the price trend of NVDA stock.\",\n",
      "    \"In my project on predicting financial trends, I applied several machine learning techniques to improve model outcomes, particularly focusing on time series forecasting.\",\n",
      "    \"This approach was newly learned and significantly enhanced the model's ability to predict NVDA stock price trends more accurately.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee's main focus was on predicting financial trends using machine learning, specifically through projects involving forecasting models and stock price predictions.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  50%|████████████████████████████                            | 5/10 [00:22<00:20,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"As for causal inference, I must admit that my knowledge in this area is quite limited, and it wasn't a focus of my previous projects.\", \n",
      "\"However, my foundational understanding of statistics and probability has laid the groundwork for future learning and application in causal inference.\"]\n",
      "reason: The retrieved pieces indicate that the interviewee has a limited knowledge of causal inference, with a basic understanding derived from a foundation in statistics and probability, but without practical experience.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  60%|█████████████████████████████████▌                      | 6/10 [00:28<00:19,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my academic experience, particularly through the financial trend prediction project I worked on, I had the opportunity to delve into applied time series modeling and machine learning forecasting applications.\",\n",
      "    \"For this project, I implemented models like NBEATS and NHITS within NeuralForecast to predict the price trends of NVDA stock.\",\n",
      "    \"These models were chosen due to their capability to handle complex patterns in time series data effectively.\",\n",
      "    \"In terms of applied time series modeling, I had a valuable experience with the financial trend prediction project I mentioned earlier.\",\n",
      "    \"I utilized NBEATS and NHITS models within NeuralForecast to predict NVDA stock price trends.\"\n",
      "]\n",
      "reason: The retrieved pieces demonstrate that the interviewee has practical experience with time series modeling, as they have worked on projects implementing specific models like NBEATS and NHITS to handle complex patterns in time series data, indicating in-depth expertise.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  70%|███████████████████████████████████████▏                | 7/10 [00:38<00:19,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"One of the key experiences I've had in developing forecasting models was during a final project for my COMP SCI 540 course, which focused on predicting financial trends using machine learning.\",\n",
      "    \"I applied the NBEATS and NHITS models within NeuralForecast to predict the price trend of NVDA stock.\",\n",
      "    \"In this project, I integrated exogenous variables like market trends, economic indicators, and industry news to enrich model insights.\",\n",
      "    \"I used Python libraries such as pandas and NumPy for statistical inference, which streamlined the training, testing, and forecasting processes.\",\n",
      "    \"The models demonstrated remarkable accuracy even in volatile markets.\",\n",
      "    \"In my projects, particularly during the financial trend prediction project, I worked extensively with large datasets.\",\n",
      "    \"I used Python as my primary tool, leveraging libraries such as pandas and NumPy for data manipulation and statistical analysis.\",\n",
      "    \"By integrating exogenous variables like market trends and economic indicators, I could provide a more comprehensive view of the data, which helped in deriving meaningful insights.\",\n",
      "    \"The use of Python's visualization tools, like Plotly, also played a crucial role in making the data trends more accessible and understandable.\",\n",
      "    \"While I didn't directly take a prototype into production, I worked on building deep neural network models using frameworks like PyTorch and TensorFlow, which are designed for scalability.\",\n",
      "    \"I collaborated with peers who had engineering backgrounds to ensure our models were optimized for performance and scalability.\",\n",
      "    \"In my academic experience, particularly within the context of my project on predicting financial trends, I have utilized statistical measures such as confidence intervals and error measurements.\",\n",
      "    \"I have a foundational understanding of these concepts from my background in statistics, where I've learned about probability distributions and statistical inference methods.\",\n",
      "    \"For this project, I implemented models like NBEATS and NHITS within NeuralForecast to predict the price trends of NVDA stock.\",\n",
      "    \"These models were chosen due to their capability to handle complex patterns in time series data effectively.\",\n",
      "    \"I integrated exogenous variables such as market trends, economic indicators, and industry news to enhance the model's insights, thereby applying a more comprehensive approach to time series analysis.\",\n",
      "    \"Throughout my education, especially in projects like the financial trend prediction one, I have extensively used Python, which is a key language in data science.\",\n",
      "    \"My responsibilities in academic projects involved building and optimizing machine learning models, conducting data analysis, and visualizing results.\",\n",
      "    \"I leveraged Python's powerful libraries, such as TensorFlow, PyTorch, pandas, and NumPy, to streamline these processes and handle large datasets efficiently.\",\n",
      "    \"In my project on predicting financial trends, I applied several machine learning techniques to improve model outcomes, particularly focusing on time series forecasting.\"\n",
      "]\n",
      "reason: The retrieved pieces focus on the interviewee's experience with developing forecasting models, using machine learning techniques, handling large datasets, and leveraging statistical measures. These activities align most closely with the responsibilities and skills typically associated with a Data Scientist.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  80%|████████████████████████████████████████████▊           | 8/10 [00:42<00:11,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my academic experience, particularly within the context of my project on predicting financial trends, I have utilized statistical measures such as confidence intervals and error measurements.\",\n",
      "    \"For example, during the evaluation phase of my models, I applied error measurements to assess the accuracy of predictions and to gauge the reliability of the models under various market conditions.\",\n",
      "    \"In my academic experience, particularly through the financial trend prediction project I worked on, I had the opportunity to delve into applied time series modeling and machine learning forecasting applications.\",\n",
      "    \"One of the key experiences I've had in developing forecasting models was during a final project for my COMP SCI 540 course, which focused on predicting financial trends using machine learning.\",\n",
      "    \"While I haven't had the opportunity to work in a machine learning or data scientist role with a large technology company yet, my academic experiences have been instrumental in preparing me for such roles.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate the interviewee has knowledge of basic machine learning theory, statistical concepts like confidence intervals, and financial market prediction, but there is no mention of familiarity with modern big data systems like Spark, making it the least supported option.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  90%|██████████████████████████████████████████████████▍     | 9/10 [00:46<00:05,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my projects, particularly during the financial trend prediction project, I worked extensively with large datasets.\",\n",
      "    \"I used Python as my primary tool, leveraging libraries such as pandas and NumPy for data manipulation and statistical analysis.\",\n",
      "    \"These libraries are quite powerful when it comes to handling complex datasets, allowing for efficient data cleaning, transformation, and analysis.\",\n",
      "    \"Throughout my education, especially in projects like the financial trend prediction one, I have extensively used Python, which is a key language in data science.\",\n",
      "    \"My responsibilities in academic projects involved building and optimizing machine learning models, conducting data analysis, and visualizing results.\",\n",
      "    \"I leveraged Python's powerful libraries, such as TensorFlow, PyTorch, pandas, and NumPy, to streamline these processes and handle large datasets efficiently.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee is very open and willing to discuss big data-related knowledge and skills, highlighting their extensive use of Python and its libraries for handling large datasets.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████| 10/10 [00:50<00:00,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"I collaborated with peers who had engineering backgrounds to ensure our models were optimized for performance and scalability.\",\n",
      "    \"Collaboration with the engineering team would then involve working closely to integrate the model into the existing infrastructure.\",\n",
      "    \"Communication is essential to understand any constraints and to iteratively refine the solution.\",\n",
      "    \"Throughout this process, maintaining open lines of communication with the engineering team would be critical to address any issues promptly and ensure the final system is both efficient and scalable.\"\n",
      "]\n",
      "reason: The retrieved pieces emphasize the Interviewee's focus on collaboration and maintaining open communication with engineering teams to ensure model optimization and scalability, aligning with the behavior pattern of a collaborative team player.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.5, 'answer_rate': 1.0}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2.evaluate_performance(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Interviewer: Thank you for joining us today. To start, could you please describe your experience in developing forecasting models? Specifically, can you share any projects where you've either developed new models or improved existing ones using scalable techniques?\n",
      " Interviewee: Thank you for having me. One of the key experiences I've had in developing forecasting models was during a final project for my COMP SCI 540 course, which focused on predicting financial trends using machine learning. I applied the NBEATS and NHITS models within NeuralForecast to predict the price trend of NVDA stock. \n",
      "\n",
      "In this project, I integrated exogenous variables like market trends, economic indicators, and industry news to enrich model insights. I used Python libraries such as pandas and NumPy for statistical inference, which streamlined the training, testing, and forecasting processes. The models demonstrated remarkable accuracy even in volatile markets. However, I did face challenges with computational costs and model complexity, which made real-time forecasting difficult. Overall, it was a valuable experience in building and applying scalable forecasting techniques.\n",
      " Interviewer: Could you elaborate on your experience with extracting and analyzing data from large, complex datasets? Specifically, what tools or techniques did you use to explain demand trends in your projects?\n",
      " Interviewee: In my projects, particularly during the financial trend prediction project, I worked extensively with large datasets. I used Python as my primary tool, leveraging libraries such as pandas and NumPy for data manipulation and statistical analysis. These libraries are quite powerful when it comes to handling complex datasets, allowing for efficient data cleaning, transformation, and analysis.\n",
      "\n",
      "When it came to explaining demand trends, I relied on my foundational understanding of machine learning and statistics. By integrating exogenous variables like market trends and economic indicators, I could provide a more comprehensive view of the data, which helped in deriving meaningful insights. The use of Python's visualization tools, like Plotly, also played a crucial role in making the data trends more accessible and understandable.\n",
      " Interviewer: Could you share an example of a project where you collaborated closely with engineering teams to build a scalable, efficient system that took a prototype into production? How did you ensure the system was scalable and efficient?\n",
      " Interviewee: During my academic journey, I had the opportunity to work on several projects where I developed machine learning models, but my primary focus was on the predictive financial trends project I mentioned earlier. While I didn't directly take a prototype into production, I worked on building deep neural network models using frameworks like PyTorch and TensorFlow, which are designed for scalability. \n",
      "\n",
      "I collaborated with peers who had engineering backgrounds to ensure our models were optimized for performance and scalability. We employed efficient data preprocessing techniques and leveraged Python libraries such as pandas and NumPy to handle data efficiently, which are essential steps before any model can be scaled or deployed.\n",
      "\n",
      "Our focus was on streamlining the training and testing processes to ensure that the models we developed could handle large datasets efficiently. Although real-time forecasting was challenging due to computational costs and model complexity, this experience was invaluable in understanding the requirements for scalable systems.\n",
      " Interviewer: Thank you for sharing your experiences. Could you tell me about your familiarity with statistical measures such as confidence intervals and significance of error measurements? How have you applied these in your projects, particularly in the context of evaluating forecasting models?\n",
      " Interviewee: In my academic experience, particularly within the context of my project on predicting financial trends, I have utilized statistical measures such as confidence intervals and error measurements. I have a foundational understanding of these concepts from my background in statistics, where I've learned about probability distributions and statistical inference methods. This knowledge has been quite beneficial when evaluating forecasting models.\n",
      "\n",
      "For example, during the evaluation phase of my models, I applied error measurements to assess the accuracy of predictions and to gauge the reliability of the models under various market conditions. Confidence intervals were particularly useful in providing a range within which the true value of the prediction likely fell, which helped in making informed decisions. My proficiency with statistical programming in Python also supported these efforts, allowing me to perform the necessary calculations and visualizations efficiently.\n",
      " Interviewer: Could you share your experience with applied time series modeling, causal inference, or machine learning forecasting applications, especially in terms of how you implemented them in your projects?\n",
      " Interviewee: In my academic experience, particularly through the financial trend prediction project I worked on, I had the opportunity to delve into applied time series modeling and machine learning forecasting applications. For this project, I implemented models like NBEATS and NHITS within NeuralForecast to predict the price trends of NVDA stock. These models were chosen due to their capability to handle complex patterns in time series data effectively.\n",
      "\n",
      "I integrated exogenous variables such as market trends, economic indicators, and industry news to enhance the model's insights, thereby applying a more comprehensive approach to time series analysis. This allowed me to provide richer forecasts and better understand underlying demand trends.\n",
      "\n",
      "While causal inference wasn't a focus of my project, my experience with machine learning forecasting has given me a strong foundation in managing data and applying sophisticated models to extract meaningful insights. The experience has been crucial in understanding the intricacies involved in time series modeling and its applications in real-world scenarios.\n",
      " Interviewer: Could you discuss any experience you have working in a machine learning or data scientist role with a large technology company? Specifically, what were your responsibilities, and how did you leverage your skills in Python or other scripting languages in that environment?\n",
      " Interviewee: While I haven't had the opportunity to work in a machine learning or data scientist role with a large technology company yet, my academic experiences have been instrumental in preparing me for such roles. Throughout my education, especially in projects like the financial trend prediction one, I have extensively used Python, which is a key language in data science.\n",
      "\n",
      "My responsibilities in academic projects involved building and optimizing machine learning models, conducting data analysis, and visualizing results. I leveraged Python's powerful libraries, such as TensorFlow, PyTorch, pandas, and NumPy, to streamline these processes and handle large datasets efficiently. These experiences have equipped me with the skills necessary to take on similar roles in a professional setting, where I am eager to apply my technical knowledge and continue learning and growing in a collaborative environment.\n",
      " Interviewer: Thank you for sharing your insights so far. I'm curious about your knowledge of applied time series modeling and causal inference. Could you provide an example where you specifically tackled challenges in these areas, and how you approached solving them?\n",
      " Interviewee: Certainly! In terms of applied time series modeling, I had a valuable experience with the financial trend prediction project I mentioned earlier. I utilized NBEATS and NHITS models within NeuralForecast to predict NVDA stock price trends. This allowed me to handle complex patterns within time series data effectively.\n",
      "\n",
      "One of the challenges I faced was integrating various exogenous variables like market trends and economic indicators to enrich the model's insights. By incorporating these elements, I could better capture underlying demand trends and improve the accuracy of forecasts. The project enhanced my understanding of time series modeling and its real-world applications.\n",
      "\n",
      "As for causal inference, I must admit that my knowledge in this area is quite limited, and it wasn't a focus of my previous projects. However, my foundational understanding of statistics and probability has laid the groundwork for future learning and application in causal inference. I'm keen to explore this further and develop a more comprehensive skill set in my future endeavors.\n",
      " Interviewer: Thank you for your detailed responses. As we wrap up, I'm curious to know, how do you approach staying updated with the latest advancements in machine learning and data science, and how do you apply new techniques to your projects?\n",
      " Interviewee: In staying updated with the latest advancements in machine learning and data science, I find it important to engage with multiple resources and communities. I regularly follow prominent machine learning and data science publications, such as arXiv and Medium, to keep abreast of the latest research and developments. Additionally, I participate in online forums and groups, like Reddit's machine learning community, where practitioners discuss trends and breakthroughs.\n",
      "\n",
      "When it comes to applying new techniques to my projects, I first evaluate their relevance to the problem at hand. If I find a new approach that could enhance the performance or efficiency of a model I'm working on, I start by experimenting in a controlled environment. I use my knowledge of machine learning frameworks like PyTorch and TensorFlow to implement and test these techniques. This hands-on experimentation allows me to understand the practical implications and potential benefits, which I can then integrate into my projects to improve outcomes.\n",
      "\n",
      "I'm always eager to learn and adapt, which I believe is essential in the ever-evolving field of machine learning and data science.\n",
      " Interviewer: Thank you for sharing how you stay updated with the latest advancements. As a final question, could you discuss any specific instance where applying a newly learned machine learning technique significantly improved the outcome of a project you were working on?\n",
      " Interviewee: In my project on predicting financial trends, I applied several machine learning techniques to improve model outcomes, particularly focusing on time series forecasting. One specific instance was the integration of exogenous variables into the models I used, such as NBEATS and NHITS, within NeuralForecast. This approach was newly learned and significantly enhanced the model's ability to predict NVDA stock price trends more accurately.\n",
      "\n",
      "By incorporating market trends, economic indicators, and industry news into the forecasting models, I enriched the insights these models provided, allowing for a more comprehensive understanding of the data. This not only improved the prediction accuracy but also provided a more detailed view of underlying demand trends.\n",
      "\n",
      "The decision to integrate these exogenous variables was influenced by staying updated with advancements in machine learning, where I learned about the benefits of including external factors in time series models. This experience reinforced the importance of continuously learning and adapting new techniques to enhance project outcomes.\n",
      " Interviewer: Thank you for sharing your experiences with us. As a final question, can you describe how you would approach collaborating with an engineering team to transition a prototype model into a fully-scalable production system, and what key steps you would focus on to ensure both efficiency and scalability?\n",
      " Interviewee: In approaching the transition of a prototype model into a fully-scalable production system, collaboration with an engineering team is crucial. While I haven't had the direct experience of taking a prototype into production, my academic projects have provided valuable insights into the foundational steps involved.\n",
      "\n",
      "Firstly, I would focus on ensuring that the model is well-optimized and efficient. This involves refining the model's architecture using frameworks like PyTorch and TensorFlow, which I have experience with, to ensure that it can handle large datasets effectively. Efficient data preprocessing is also key, and I would leverage libraries such as pandas and NumPy to clean and transform the data adequately.\n",
      "\n",
      "Collaboration with the engineering team would then involve working closely to integrate the model into the existing infrastructure. This might require adapting the model to fit within specific system requirements and ensuring compatibility with the production environment. Communication is essential to understand any constraints and to iteratively refine the solution.\n",
      "\n",
      "Lastly, I would focus on scalability, perhaps by utilizing platforms like TensorFlow Serving or ONNX to deploy the model in a way that can easily scale with increasing data volumes and demand. Throughout this process, maintaining open lines of communication with the engineering team would be critical to address any issues promptly and ensure the final system is both efficient and scalable.\n"
     ]
    }
   ],
   "source": [
    "print(conv2.agent_b.hist_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = \"../data/scripts/job/data_scientist_concise.json\"\n",
    "q_path = \"../data/questionnaires/data_scientist_concise_q.json\"\n",
    "config_path = \"../config/backbone/backbone_configs.json\"\n",
    "conv = conversation.make_conversation(s_path, q_path, config_path, itr_num=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative conversation: 100%|████████████████████████████████████████████████████| 10/10 [00:35<00:00,  3.58s/it]\n"
     ]
    }
   ],
   "source": [
    "conv.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Interviewer: Thank you for joining us today. To start, can you tell me about your experience with developing forecasting models? Specifically, have you had the opportunity to improve existing models using scalable techniques, and if so, could you share an example from your project experience?\n",
      " Interviewee: In my final project for the course COMP SCI 540 — Introduction to Artificial Intelligence, I developed forecasting models to predict financial trends, specifically applying NBEATS and NHITS models within NeuralForecast to predict NVDA stock price trends. I integrated exogenous variables to enhance model insights and streamlined the training, testing, and forecasting processes. This led to remarkable accuracy, although real-time forecasting remained challenging due to computational costs and model complexity.\n",
      " Interviewer: Could you describe a time when you extracted data from large, complex datasets for analysis and model development? What challenges did you face and how did you address them?\n",
      " Interviewee: In my project on predicting financial trends, I worked with complex datasets by integrating exogenous variables such as market trends and economic indicators. I used Python libraries like pandas and NumPy for data extraction and analysis. One challenge was ensuring data quality, which I addressed by performing data preprocessing and cleansing tasks to maintain accuracy in the model development process.\n",
      " Interviewer: Can you tell me about a time when you collaborated with engineering teams to build scalable and efficient systems for deploying prototypes into production? What was your role in this process, and what challenges did you encounter?\n",
      " Interviewee: In my previous project experience, I primarily focused on developing forecasting models and analyzing data. While I haven't had direct collaboration with engineering teams for deploying prototypes into production, I am familiar with model deployment platforms like TensorFlow Serving and ONNX, which are designed to facilitate scalable deployments.\n",
      " Interviewer: Based on your project experience, could you elaborate on how you've applied time series modeling or causal inference techniques in your work? Additionally, have you worked on any machine learning forecasting applications, and how did you ensure their accuracy and reliability?\n",
      " Interviewee: In my project on predicting financial trends, I applied time series modeling by using NBEATS and NHITS models within NeuralForecast. These models helped forecast NVDA stock price trends by integrating exogenous variables, which enhanced their accuracy. I haven't worked with causal inference techniques, but the focus was on ensuring the reliability of machine learning forecasting applications through data preprocessing and careful model training and testing.\n",
      " Interviewer: \n",
      "Could you share your experience with statistical measures such as confidence intervals and significance of error measurements in your projects? How did you apply these concepts to evaluate and validate your forecasting models?\n",
      " Interviewee: In my project experience, I utilized statistical measures such as confidence intervals to evaluate and validate forecasting models. These concepts were applied to assess the model's accuracy and reliability by estimating the uncertainty of predictions. The focus was on ensuring that the models provided reliable forecasts within an acceptable margin of error, using Python libraries to facilitate this evaluation process.\n",
      " Interviewer: \n",
      "Based on your experience with machine learning and your project on predicting financial trends, could you share how you utilized scripting languages like Python or any other to automate and enhance your model development process?\n",
      " Interviewee: In my project on predicting financial trends, I utilized Python to automate data preprocessing and enhance the model development process. Libraries like pandas and NumPy were used for data extraction and statistical inference, which streamlined tasks and improved efficiency.\n",
      " Interviewer: Could you elaborate on your experience with applied time series modeling, specifically any challenges you encountered during the forecasting process and how you addressed them?\n",
      " Interviewee: In my project on predicting financial trends, I applied time series modeling using NBEATS and NHITS models within NeuralForecast to forecast NVDA stock price trends. A challenge was dealing with the computational costs and model complexity, which made real-time forecasting difficult. I addressed this by streamlining training, testing, and forecasting processes to maintain model accuracy.\n",
      " Interviewer: Given your project experience in predicting financial trends and your expertise in Python, can you discuss how you've used your knowledge of statistical measures like significance of error measurements to refine and improve the accuracy of your models?\n",
      " Interviewee: In my project on predicting financial trends, I used Python to apply statistical measures such as the significance of error measurements. These measures were essential for refining and improving model accuracy by identifying areas where predictions were less reliable and adjusting the model accordingly. This approach helped ensure that the models maintained high levels of accuracy throughout the forecasting process.\n",
      " Interviewer: Given your experience with Python and your use of statistical measures for improving model accuracy, could you elaborate on any specific challenges you faced when evaluating model performance using these statistical methods, and how you overcame them to ensure reliable forecasting outcomes?\n",
      " Interviewee: In evaluating model performance using statistical methods like confidence intervals and error measurements, a key challenge was ensuring the accuracy of these metrics to validate the forecasts. I addressed this by meticulously applying data preprocessing and cleansing techniques to maintain data integrity, which helped ensure the statistical measures provided reliable insights into model performance.\n",
      " Interviewer: Based on your project experience and understanding of forecasting models, how do you envision collaborating with engineering teams in the future to ensure the effective deployment of models into production?\n",
      " Interviewee: In the future, I envision collaborating with engineering teams by leveraging my familiarity with model deployment platforms like TensorFlow Serving and ONNX. My focus would be on integrating the forecasting models effectively into scalable and efficient systems, ensuring seamless transition from prototype to production.\n"
     ]
    }
   ],
   "source": [
    "print(conv.agent_b.hist_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  10%|█████▌                                                  | 1/10 [00:01<00:14,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: []\n",
      "reason: The retrieved relevant pieces do not contain any information about the interviewee's degree, making it impossible to determine the correct answer from the multiple-choice options.\n",
      "answer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  20%|███████████▏                                            | 2/10 [00:03<00:14,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: []\n",
      "reason: The retrieved relevant pieces do not contain any information about the interviewee's previous working experience, making it impossible to determine the correct answer from the multiple-choice options.\n",
      "answer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  30%|████████████████▊                                       | 3/10 [00:08<00:21,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my project on predicting financial trends, I worked with complex datasets by integrating exogenous variables such as market trends and economic indicators. I used Python libraries like pandas and NumPy for data extraction and analysis.\",\n",
      "    \"In my project on predicting financial trends, I utilized Python to automate data preprocessing and enhance the model development process. Libraries like pandas and NumPy were used for data extraction and statistical inference, which streamlined tasks and improved efficiency.\",\n",
      "    \"In my project on predicting financial trends, I used Python to apply statistical measures such as the significance of error measurements.\"\n",
      "]\n",
      "reason: The retrieved relevant pieces indicate that the interviewee extensively uses Python and its libraries like pandas and NumPy for statistical work, but there is no mention of R or PyG. This suggests that PyG might not be part of the interviewee's skill set.\n",
      "answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  40%|██████████████████████▍                                 | 4/10 [00:11<00:20,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my final project for the course COMP SCI 540 — Introduction to Artificial Intelligence, I developed forecasting models to predict financial trends, specifically applying NBEATS and NHITS models within NeuralForecast to predict NVDA stock price trends.\",\n",
      "    \"In my project on predicting financial trends, I worked with complex datasets by integrating exogenous variables such as market trends and economic indicators.\",\n",
      "    \"In my project on predicting financial trends, I applied time series modeling by using NBEATS and NHITS models within NeuralForecast.\",\n",
      "    \"In my project on predicting financial trends, I used Python to apply statistical measures such as the significance of error measurements.\"\n",
      "]\n",
      "reason: The retrieved pieces consistently highlight the interviewee's experience in developing forecasting models to predict financial trends, using machine learning models like NBEATS and NHITS, and integrating complex datasets with economic indicators. This indicates that the interviewee's main focus has been on predicting financial trends using machine learning.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  50%|████████████████████████████                            | 5/10 [00:14<00:15,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"I haven't worked with causal inference techniques, but the focus was on ensuring the reliability of machine learning forecasting applications through data preprocessing and careful model training and testing.\"]\n",
      "reason: The retrieved pieces indicate that the interviewee has not worked with causal inference techniques, suggesting a lack of practical experience. This aligns with having a basic understanding without practice.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  60%|█████████████████████████████████▌                      | 6/10 [00:18<00:13,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my final project for the course COMP SCI 540 — Introduction to Artificial Intelligence, I developed forecasting models to predict financial trends, specifically applying NBEATS and NHITS models within NeuralForecast to predict NVDA stock price trends.\",\n",
      "    \"In my project on predicting financial trends, I applied time series modeling by using NBEATS and NHITS models within NeuralForecast.\",\n",
      "    \"In my project on predicting financial trends, I applied time series modeling using NBEATS and NHITS models within NeuralForecast to forecast NVDA stock price trends.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has applied time series modeling in their project, specifically mentioning the use of NBEATS and NHITS models within NeuralForecast to forecast financial trends. This suggests a practical application and some experience with time series modeling, but does not necessarily indicate in-depth expertise beyond their project work.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  70%|███████████████████████████████████████▏                | 7/10 [00:23<00:12,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my final project for the course COMP SCI 540 — Introduction to Artificial Intelligence, I developed forecasting models to predict financial trends, specifically applying NBEATS and NHITS models within NeuralForecast to predict NVDA stock price trends.\",\n",
      "    \"I integrated exogenous variables to enhance model insights and streamlined the training, testing, and forecasting processes.\",\n",
      "    \"In my project on predicting financial trends, I worked with complex datasets by integrating exogenous variables such as market trends and economic indicators.\",\n",
      "    \"I used Python libraries like pandas and NumPy for data extraction and analysis.\",\n",
      "    \"I utilized statistical measures such as confidence intervals to evaluate and validate forecasting models.\",\n",
      "    \"In my project on predicting financial trends, I utilized Python to automate data preprocessing and enhance the model development process.\",\n",
      "    \"Libraries like pandas and NumPy were used for data extraction and statistical inference, which streamlined tasks and improved efficiency.\",\n",
      "    \"In my project on predicting financial trends, I used Python to apply statistical measures such as the significance of error measurements.\",\n",
      "    \"These measures were essential for refining and improving model accuracy by identifying areas where predictions were less reliable and adjusting the model accordingly.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate the interviewee's experience in developing forecasting models, working with complex datasets, utilizing Python for data analysis, and applying statistical measures, which aligns closely with the role of a Data Scientist.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  80%|████████████████████████████████████████████▊           | 8/10 [00:26<00:07,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my project on predicting financial trends, I applied time series modeling by using NBEATS and NHITS models within NeuralForecast.\",\n",
      "    \"I haven't worked with causal inference techniques, but the focus was on ensuring the reliability of machine learning forecasting applications through data preprocessing and careful model training and testing.\",\n",
      "    \"In my project experience, I utilized statistical measures such as confidence intervals to evaluate and validate forecasting models.\",\n",
      "    \"In my project on predicting financial trends, I used Python to apply statistical measures such as the significance of error measurements.\"\n",
      "]\n",
      "reason: The retrieved pieces provide evidence that the interviewee has experience with forecasting models in financial market prediction and utilizes statistical measures like confidence intervals. However, there is no mention of familiarity with modern big data systems like Spark, suggesting a gap in this area.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  90%|██████████████████████████████████████████████████▍     | 9/10 [00:29<00:03,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"In my project on predicting financial trends, I worked with complex datasets by integrating exogenous variables such as market trends and economic indicators.\",\n",
      "\"I used Python libraries like pandas and NumPy for data extraction and analysis.\",\n",
      "\"One challenge was ensuring data quality, which I addressed by performing data preprocessing and cleansing tasks to maintain accuracy in the model development process.\"]\n",
      "reason: The retrieved pieces show that the interviewee has experience with handling complex datasets, using Python for data extraction and analysis, and addressing challenges like data quality through preprocessing. These points indicate a willingness to discuss big data-related knowledge and skills when relevant.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████| 10/10 [00:32<00:00,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my previous project experience, I primarily focused on developing forecasting models and analyzing data.\",\n",
      "    \"While I haven't had direct collaboration with engineering teams for deploying prototypes into production, I am familiar with model deployment platforms like TensorFlow Serving and ONNX, which are designed to facilitate scalable deployments.\",\n",
      "    \"In the future, I envision collaborating with engineering teams by leveraging my familiarity with model deployment platforms like TensorFlow Serving and ONNX.\",\n",
      "    \"My focus would be on integrating the forecasting models effectively into scalable and efficient systems, ensuring seamless transition from prototype to production.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has not yet collaborated with engineering teams but expresses a willingness and familiarity with relevant deployment platforms, suggesting they are not currently a collaborative team player but may aspire to be.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.4, 'answer_rate': 0.8}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.evaluate_performance(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## buyer: startup cfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/questionnaires/startup_cfo_normal_q.json\", \"r\") as f:\n",
    "    questionnaire = json.load(f)\n",
    "with open(\"../data/scripts/buyer/startup_cfo_normal.json\", \"r\") as f:\n",
    "    script = json.load(f)\n",
    "with open(\"../config/backbone/backbone_configs.json\", \"r\") as f:\n",
    "    backbone_configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr_num = 10\n",
    "a_params = script[\"Public\"]\n",
    "a_params[\"itr_num\"] = itr_num\n",
    "b_params = {\"script_path\":\"../data/scripts/buyer/startup_cfo_normal.json\",\n",
    "            \"role_a\":\"Salesperson\",\n",
    "            \"role_b\":\"Buyer\"}\n",
    "c_params = {\"role_a\":\"Salesperson\",\n",
    "            \"role_b\":\"Buyer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = conversation.Conversation(a_params, b_params, questionnaire, c_params, backbone_configs, itr_num, sce=\"b2b negotiation\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative conversation: 100%|████████████████████████████████████████████████████████| 10/10 [00:41<00:00,  4.10s/it]\n"
     ]
    }
   ],
   "source": [
    "conv.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████████| 10/10 [00:35<00:00,  3.58s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8, 'answer_rate': 0.8}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.evaluate_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  10%|██████                                                      | 1/10 [00:04<00:43,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Additionally, managing compliance with financial regulations and understanding fintech-specific legal requirements are crucial for us.\",\n",
      "    \"We are particularly interested in finding cost-effective legal solutions that can scale with our growth while offering flexibility and clear value metrics.\",\n",
      "    \"We're very much inclined towards cost-effective solutions, and in this regard, I favor flexible engagement models.\",\n",
      "    \"This approach aligns well with our preference for clear value metrics, ensuring we understand exactly what we are getting for our investment.\",\n",
      "    \"Balancing cost efficiency while ensuring robust legal support is critical for us, especially as we navigate complex regulatory landscapes across multiple jurisdictions.\",\n",
      "    \"We prioritize implementing solutions that can seamlessly integrate with our existing infrastructure and provide comprehensive compliance monitoring across all markets we operate in.\",\n",
      "    \"Additionally, we assess the integration capabilities of these tools with our existing systems, ensuring they support seamless operations and do not disrupt our workflow.\",\n",
      "    \"Moreover, cost-effectiveness and the scalability of the solution are key factors, as they need to align with our budget management goals and accommodate our growth.\",\n",
      "    \"We also place a strong emphasis on cost-effectiveness, ensuring that any investments in scaling our compliance systems align with our budget management goals.\",\n",
      "    \"By prioritizing solutions that are both cost-effective and scalable, we've been able to align our compliance efforts with our overall growth objectives.\"\n",
      "]\n",
      "reason: The retrieved pieces emphasize the Buyer's focus on cost-effectiveness and scalability in legal services, indicating that these are primary concerns. This aligns with the Buyer's interest in flexible and scalable solutions that meet their budget management and growth objectives.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  20%|████████████                                                | 2/10 [00:07<00:29,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Historically, we've focused on optimizing resource allocation to ensure maximum ROI.\",\n",
      "    \"We're very much inclined towards cost-effective solutions, and in this regard, I favor flexible engagement models.\",\n",
      "    \"For instance, hybrid billing models that balance hourly billing with retainer structures have proven effective for us, as they offer predictability in costs while still allowing for flexibility as our needs change.\",\n",
      "    \"This approach aligns well with our preference for clear value metrics, ensuring we understand exactly what we are getting for our investment.\"\n",
      "]\n",
      "reason: The retrieved pieces clearly indicate that the Buyer prefers a hybrid billing model, as they explicitly mention favoring flexible engagement models and hybrid billing models that balance hourly billing with retainer structures. This preference is due to the predictability in costs and flexibility they provide.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  30%|██████████████████                                          | 3/10 [00:12<00:28,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Indeed, with our recent expansion into international markets like the UK, Singapore, and Germany, we've encountered a few legal challenges.\",\n",
      "    \"Primarily, we're focused on navigating cross-border regulatory compliance and ensuring our intellectual property rights are well-protected across these jurisdictions.\",\n",
      "    \"Furthermore, we assess the legal partner's ability to proactively manage risks and offer solutions that scale with our growth, particularly in new international markets.\",\n",
      "    \"At InnovateX, scaling our compliance systems as we expand into new markets is a critical aspect of our strategic planning.\",\n",
      "    \"Our approach to scalability focuses on ensuring that our systems are both robust and adaptable to meet the diverse regulatory requirements across different jurisdictions.\",\n",
      "    \"We prioritize implementing solutions that can seamlessly integrate with our existing infrastructure and provide comprehensive compliance monitoring across all markets we operate in.\"\n",
      "]\n",
      "reason: The retrieved relevant pieces indicate that InnovateX has recently expanded into international markets such as the UK, Singapore, and Germany, suggesting that the CFO has experience with global operations. However, the precise duration of this experience is not mentioned, which makes it difficult to confidently select between 2 years or 5+ years of experience.\n",
      "answer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  40%|████████████████████████                                    | 4/10 [00:14<00:18,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"One of the success factors we've identified is the importance of a proactive risk management framework.\",\n",
      "\"By developing and continuously refining our risk assessment processes, we've been able to anticipate potential regulatory challenges and address them before they escalate.\"]\n",
      "reason: The retrieved pieces indicate that the Buyer emphasizes a proactive risk management framework, focusing on continuous risk assessment and mitigation before issues arise, which aligns with a systematic and proactive approach.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  50%|██████████████████████████████                              | 5/10 [00:17<00:16,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Historically, we've focused on optimizing resource allocation to ensure maximum ROI.\",\n",
      "    \"We're very much inclined towards cost-effective solutions, and in this regard, I favor flexible engagement models.\",\n",
      "    \"For instance, hybrid billing models that balance hourly billing with retainer structures have proven effective for us, as they offer predictability in costs while still allowing for flexibility as our needs change.\",\n",
      "    \"This approach aligns well with our preference for clear value metrics, ensuring we understand exactly what we are getting for our investment.\",\n",
      "    \"Balancing cost efficiency while ensuring robust legal support is critical for us, especially as we navigate complex regulatory landscapes across multiple jurisdictions.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the CFO of InnovateX has a strong focus on optimizing resource allocation to ensure maximum ROI, favors flexible engagement models, and emphasizes cost-effectiveness in their legal services approach. This aligns with option B, which emphasizes ROI and cost optimization.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  60%|████████████████████████████████████                        | 6/10 [00:21<00:14,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Indeed, with our recent expansion into international markets like the UK, Singapore, and Germany, we've encountered a few legal challenges. Primarily, we're focused on navigating cross-border regulatory compliance and ensuring our intellectual property rights are well-protected across these jurisdictions.\",\n",
      "    \"Additionally, managing compliance with financial regulations and understanding fintech-specific legal requirements are crucial for us.\",\n",
      "    \"Furthermore, we look for innovative approaches that align with our emphasis on technology integration. For example, understanding the legal implications of AI implementation and data protection within the fintech space is paramount.\",\n",
      "    \"At InnovateX, scaling our compliance systems as we expand into new markets is a critical aspect of our strategic planning.\",\n",
      "    \"Our approach to scalability focuses on ensuring that our systems are both robust and adaptable to meet the diverse regulatory requirements across different jurisdictions.\",\n",
      "    \"By developing and continuously refining our risk assessment processes, we've been able to anticipate potential regulatory challenges and address them before they escalate.\",\n",
      "    \"Strategically, forming partnerships with legal experts who have a deep understanding of cross-border regulatory compliance has been invaluable.\",\n",
      "    \"These partnerships have provided us with the insights needed to navigate the complexities of diverse regulatory environments.\",\n",
      "    \"By prioritizing solutions that are both cost-effective and scalable, we've been able to align our compliance efforts with our overall growth objectives.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the Buyer, who appears to be in a CFO role, demonstrates a moderate understanding of legal compliance, emphasizing the importance of regulatory compliance and the need for expert partnerships to navigate diverse environments. This suggests the Buyer relies on expert validation rather than possessing an expert-level understanding themselves.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  70%|██████████████████████████████████████████                  | 7/10 [00:25<00:10,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"We utilize a variety of legal tech solutions to enhance our operational efficiency and ensure robust compliance.\",\n",
      "    \"For instance, we are familiar with AI-driven tools that help with compliance monitoring and data protection, which are crucial for our fintech operations.\",\n",
      "    \"We are interested in platforms that offer comprehensive support, particularly those that can adapt to different jurisdictions and provide real-time insights into compliance challenges.\",\n",
      "    \"We also assess the integration capabilities of these tools with our existing systems, ensuring they support seamless operations and do not disrupt our workflow.\",\n",
      "    \"The ability of a tool to offer clear and actionable insights, particularly in the realm of AI governance and data protection, is essential, as it aligns with our fintech operations and strategic objectives.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the Buyer places a high value on technology integration, specifically using advanced tools for compliance monitoring and data protection, which are crucial for their operations. This shows high confidence in technology and understanding of its legal implications.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  80%|████████████████████████████████████████████████            | 8/10 [00:28<00:06,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"We're very much inclined towards cost-effective solutions, and in this regard, I favor flexible engagement models.\",\n",
      "    \"For instance, hybrid billing models that balance hourly billing with retainer structures have proven effective for us, as they offer predictability in costs while still allowing for flexibility as our needs change.\",\n",
      "    \"This approach aligns well with our preference for clear value metrics, ensuring we understand exactly what we are getting for our investment.\",\n",
      "    \"Balancing cost efficiency while ensuring robust legal support is critical for us, especially as we navigate complex regulatory landscapes across multiple jurisdictions.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate a preference for cost-effective and flexible engagement models with a focus on clear value metrics, suggesting a pragmatic approach to negotiating service terms.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  90%|██████████████████████████████████████████████████████      | 9/10 [00:30<00:03,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Indeed, with our recent expansion into international markets like the UK, Singapore, and Germany, we've encountered a few legal challenges.\",\n",
      "    \"Primarily, we're focused on navigating cross-border regulatory compliance and ensuring our intellectual property rights are well-protected across these jurisdictions.\",\n",
      "    \"Managing compliance with financial regulations and understanding fintech-specific legal requirements are crucial for us.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the Buyer emphasized cross-border compliance challenges, mentioning their focus on navigating regulatory compliance and intellectual property protection across international markets. This suggests a clear connection between international expansion and legal needs.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████████| 10/10 [00:31<00:00,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: []\n",
      "reason: The retrieved relevant pieces do not contain any information regarding the priority level given by the CFO to IP protection, making it impossible to determine the correct answer from the multiple-choice options.\n",
      "answer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B', 'C', 'None', 'B', 'B', 'B', 'B', 'B', 'B', 'None']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.agent_c.answer_all(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## guest: climate activist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/questionnaires/climate_activist_normal_q.json\", \"r\") as f:\n",
    "    questionnaire = json.load(f)\n",
    "with open(\"../data/scripts/guest/climate_activist_normal.json\", \"r\") as f:\n",
    "    script = json.load(f)\n",
    "with open(\"../config/backbone/backbone_configs.json\", \"r\") as f:\n",
    "    backbone_configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr_num = 5\n",
    "a_params = script[\"Public\"]\n",
    "a_params[\"itr_num\"] = itr_num\n",
    "b_params = {\"script_path\":\"../data/scripts/guest/climate_activist_normal.json\",\n",
    "            \"role_a\":\"Host\",\n",
    "            \"role_b\":\"Guest\"}\n",
    "c_params = {\"role_a\":\"Host\",\n",
    "            \"role_b\":\"Guest\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = conversation.Conversation(a_params, b_params, questionnaire, c_params, backbone_configs, itr_num, sce=\"podcast interview\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative conversation: 100%|██████████████████████████████████████████████████████| 5/5 [00:36<00:00,  7.37s/it]\n"
     ]
    }
   ],
   "source": [
    "conv.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████| 10/10 [00:37<00:00,  3.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.9, 'answer_rate': 0.9}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.evaluate_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  10%|█████▌                                                  | 1/10 [00:03<00:35,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Corporations must be held accountable for their environmental impact and should lead the transition to sustainable practices.\",\n",
      "    \"To move from mere pledges to genuine, impactful action, companies need to implement transparent and comprehensive environmental strategies that go beyond greenwashing.\",\n",
      "    \"Firstly, I believe corporations should commit to robust emissions reporting and set clear, measurable targets for reducing their carbon footprint.\",\n",
      "    \"Moreover, they should actively engage in and support divestment campaigns, shifting investments away from fossil fuels and towards renewable energy solutions.\"\n",
      "]\n",
      "reason: The retrieved pieces emphasize that corporations must be held accountable for their environmental impact and should engage in specific actions such as emissions reporting and divestment from fossil fuels. This aligns with option B, as it indicates a necessity for legal or formal accountability rather than voluntary actions.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  20%|███████████▏                                            | 2/10 [00:07<00:31,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Furthermore, one effective approach has been highlighting the intersections between climate policy and social justice.\",\n",
      "    \"A crucial lesson has been the need to center marginalized communities in our efforts.\",\n",
      "    \"This focus on climate justice has shaped my activism to be more inclusive and holistic, ensuring that those most affected have their voices heard and respected.\",\n",
      "    \"In envisioning the future of climate action, the major change I would like to see is a societal shift towards prioritizing climate justice.\",\n",
      "    \"This means ensuring that our approach to addressing climate change is deeply rooted in social equity, recognizing that marginalized communities bear the brunt of environmental impacts and must be at the forefront of solution-building.\"\n",
      "]\n",
      "reason: The retrieved pieces consistently highlight the Guest's view that climate justice is fundamentally linked to environmental activism. This is evident in their focus on social equity, prioritizing marginalized communities, and advocating for climate justice as a core aspect of climate action.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  30%|████████████████▊                                       | 3/10 [00:10<00:24,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"Additionally, my involvement in direct actions, like organizing sit-ins and protests, reinforced the impact of peaceful civil disobedience in driving attention to urgent issues.\",\n",
      "\"It requires courage and careful planning, but these actions have a remarkable ability to disrupt complacency and compel people to listen.\"]\n",
      "reason: The retrieved pieces clearly indicate that the activist believes in peaceful civil disobedience, as demonstrated by their involvement in organizing sit-ins and protests, which are non-violent forms of direct action.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  40%|██████████████████████▍                                 | 4/10 [00:13<00:18,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"To move from mere pledges to genuine, impactful action, companies need to implement transparent and comprehensive environmental strategies that go beyond greenwashing.\"]\n",
      "reason: The retrieved piece clearly indicates that the activist believes companies need to go beyond greenwashing, which implies a strong criticism of deceptive environmental marketing practices.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  50%|████████████████████████████                            | 5/10 [00:17<00:17,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Marginalized communities are disproportionately affected by these changes, which is something I'm deeply passionate about addressing.\",\n",
      "    \"Furthermore, one effective approach has been highlighting the intersections between climate policy and social justice.\",\n",
      "    \"By emphasizing how climate change disproportionately affects marginalized communities, we push for policies that are not only environmentally sustainable but also socially equitable.\",\n",
      "    \"A crucial lesson has been the need to center marginalized communities in our efforts.\",\n",
      "    \"This focus on climate justice has shaped my activism to be more inclusive and holistic, ensuring that those most affected have their voices heard and respected.\",\n",
      "    \"In envisioning the future of climate action, the major change I would like to see is a societal shift towards prioritizing climate justice.\",\n",
      "    \"This means ensuring that our approach to addressing climate change is deeply rooted in social equity, recognizing that marginalized communities bear the brunt of environmental impacts and must be at the forefront of solution-building.\",\n",
      "    \"By amplifying the voices of those most affected and ensuring they have a seat at the decision-making table, we can create more equitable and effective climate strategies.\"\n",
      "]\n",
      "reason: The retrieved pieces consistently emphasize the impact of climate change on marginalized communities and the importance of integrating social equity into environmental strategies. This clearly connects climate change to social issues through the lens of how it disproportionately affects these communities.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  60%|█████████████████████████████████▌                      | 6/10 [00:21<00:14,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Based on my activism and involvement in environmental movements, I see these challenges continuing to evolve, with a greater urgency for immediate and comprehensive action.\",\n",
      "    \"The science is clear, and it's vital that we implement effective climate policies and hold corporations accountable for their environmental impact.\",\n",
      "    \"A key strategy has been the direct engagement with policymakers through peaceful direct actions, such as sit-ins and organized rallies.\",\n",
      "    \"By emphasizing how climate change disproportionately affects marginalized communities, we push for policies that are not only environmentally sustainable but also socially equitable.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the activist has a nuanced understanding of climate policies while advocating for stronger action. They emphasize the need for immediate and comprehensive measures and highlight the importance of equitable and sustainable policies, suggesting that they are not fully satisfied with current efforts.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  70%|███████████████████████████████████████▏                | 7/10 [00:24<00:10,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Organizing the largest climate march in our city, with over 5,000 participants, taught me that when people unite for a common cause, the collective voice becomes incredibly powerful.\",\n",
      "    \"This experience emphasized the significance of community engagement and the need to build coalitions that bring together diverse perspectives and strengths.\"\n",
      "]\n",
      "reason: The retrieved pieces highlight the activist's view that community engagement is crucial for effective climate advocacy, as it brings people together for a common cause, amplifying their collective voice and emphasizing diverse perspectives and strengths.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  80%|████████████████████████████████████████████▊           | 8/10 [00:30<00:08,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Marginalized communities are disproportionately affected by these changes, which is something I'm deeply passionate about addressing.\",\n",
      "    \"Furthermore, one effective approach has been highlighting the intersections between climate policy and social justice.\",\n",
      "    \"It's about ensuring that those most impacted have a seat at the table and that their voices guide the solutions we pursue.\",\n",
      "    \"A crucial lesson has been the need to center marginalized communities in our efforts.\",\n",
      "    \"Climate change doesn't affect everyone equally, and it's essential that solutions are crafted with an understanding of social justice.\",\n",
      "    \"This focus on climate justice has shaped my activism to be more inclusive and holistic, ensuring that those most affected have their voices heard and respected.\",\n",
      "    \"In envisioning the future of climate action, the major change I would like to see is a societal shift towards prioritizing climate justice.\",\n",
      "    \"This means ensuring that our approach to addressing climate change is deeply rooted in social equity, recognizing that marginalized communities bear the brunt of environmental impacts and must be at the forefront of solution-building.\",\n",
      "    \"I hope to play a significant role in making this a reality by continuing to advocate for policies that integrate environmental sustainability with social justice.\",\n",
      "    \"By amplifying the voices of those most affected and ensuring they have a seat at the decision-making table, we can create more equitable and effective climate strategies.\"\n",
      "]\n",
      "reason: The retrieved pieces consistently highlight the Guest's strong commitment to climate justice issues, emphasizing the need to prioritize social equity and empower marginalized communities in climate strategies. This indicates an absolute conviction about these issues.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  90%|██████████████████████████████████████████████████▍     | 9/10 [00:33<00:04,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"The science is clear, and it's vital that we implement effective climate policies and hold corporations accountable for their environmental impact.\",\n",
      "    \"Furthermore, one effective approach has been highlighting the intersections between climate policy and social justice.\",\n",
      "    \"Through ongoing activism and community engagement, I aim to foster greater awareness and understanding of the interconnectedness of environmental and social issues.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the activist uses scientific understanding to inform advocacy, as they emphasize the clarity of science in implementing effective climate policies and highlight the interconnectedness of environmental and social issues through their activism.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████| 10/10 [00:37<00:00,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"A crucial lesson has been the need to center marginalized communities in our efforts.\",\n",
      "\"Climate change doesn't affect everyone equally, and it's essential that solutions are crafted with an understanding of social justice.\",\n",
      "\"This focus on climate justice has shaped my activism to be more inclusive and holistic, ensuring that those most affected have their voices heard and respected.\",\n",
      "\"In envisioning the future of climate action, the major change I would like to see is a societal shift towards prioritizing climate justice.\",\n",
      "\"This means ensuring that our approach to addressing climate change is deeply rooted in social equity, recognizing that marginalized communities bear the brunt of environmental impacts and must be at the forefront of solution-building.\",\n",
      "\"By amplifying the voices of those most affected and ensuring they have a seat at the decision-making table, we can create more equitable and effective climate strategies.\"]\n",
      "reason: The retrieved pieces emphasize the activist's commitment to centering marginalized communities and prioritizing social equity in climate solutions, suggesting that indigenous perspectives are likely included in their holistic approach to climate justice.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'C', 'B', 'B', 'B', 'B', 'C', 'B', 'B']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.agent_c.answer_all(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
