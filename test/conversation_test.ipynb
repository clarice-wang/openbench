{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "sys.path.append('../src/')\n",
    "import oracle\n",
    "import prompts\n",
    "import agent_a\n",
    "import agent_b\n",
    "import agent_c\n",
    "import conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'conversation' from '/Users/shiyimin/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Projects/llm_lead/interviews/test/../src/conversation.py'>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(prompts)\n",
    "importlib.reload(agent_a)\n",
    "importlib.reload(agent_b)\n",
    "importlib.reload(agent_c)\n",
    "importlib.reload(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## job: data scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### slight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = \"../data/scripts/job/data_scientist_slight.json\"\n",
    "q_path = \"../data/questionnaires/data_scientist_slight_q.json\"\n",
    "config_path = \"../config/backbone/backbone_configs.json\"\n",
    "conv = conversation.make_conversation(s_path, q_path, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative conversation: 100%|████████████████████████████████████████████████████| 10/10 [00:56<00:00,  5.68s/it]\n"
     ]
    }
   ],
   "source": [
    "conv.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  10%|█████▌                                                  | 1/10 [00:02<00:25,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: []\n",
      "reason: The retrieved relevant pieces do not contain any information about the interviewee's degree, making it impossible to determine the correct answer from the multiple-choice options.\n",
      "answer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  20%|███████████▏                                            | 2/10 [00:07<00:29,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"In my experience, I haven't yet had the opportunity to work directly with large technology companies in a formal role.\",\n",
      "\"My experience with machine learning forecasting applications is primarily rooted in my academic projects, like the financial trends prediction project I previously mentioned.\",\n",
      "\"While I have not yet had the chance to apply these skills in a large technology company setting, I am confident that my solid foundation in machine learning, coupled with my proficiency in Python and statistics, would enable me to contribute effectively to similar forecasting applications in such environments.\"]\n",
      "reason: The retrieved relevant pieces clearly indicate that the interviewee has not had any formal work experience with large technology companies, and their experience is primarily from academic projects.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  30%|████████████████▊                                       | 3/10 [00:10<00:25,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Beyond Python, I have experience with R for statistical analysis and SQL for data extraction and management.\",\n",
      "    \"Python is a core part of my skill set, and I've leveraged its capabilities extensively in my projects, particularly for data analysis and model development.\",\n",
      "    \"I'm proficient in using Python libraries such as pandas, NumPy, and SciPy for data manipulation and statistical inference, which are crucial in managing and analyzing large datasets efficiently.\"\n",
      "]\n",
      "reason: The retrieved pieces clearly indicate that the Interviewee is skilled in Python, R, and Python libraries like pandas for statistical analysis. However, there is no mention of PyG, suggesting it is not part of the Interviewee's skill set for statistics work.\n",
      "answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  40%|██████████████████████▍                                 | 4/10 [00:17<00:28,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my final project for the COMP SCI 540 course, I focused on predicting financial trends using machine learning.\",\n",
      "    \"I applied state-of-the-art models such as NBEATS and NHITS within the NeuralForecast framework to predict the price trends of NVDA stock.\",\n",
      "    \"During the financial trends prediction project, I dealt with large datasets and focused on the initial stages of data extraction and preparation for model development.\",\n",
      "    \"In my experience, particularly during the financial trends prediction project, I've utilized applied time series modeling extensively.\",\n",
      "    \"In the financial trends prediction project, I used Python to streamline the data preprocessing and model training processes.\",\n",
      "    \"In my forecasting projects, I've consistently applied statistical concepts to enhance the robustness and reliability of the models.\",\n",
      "    \"In my machine learning forecasting applications, particularly the financial trends prediction project, I applied advanced models like NBEATS and NHITS to forecast NVDA stock price trends.\"\n",
      "]\n",
      "reason: The retrieved pieces clearly indicate that the interviewee's main focus in previous experience was on predicting financial trends using machine learning, as they consistently mention projects related to financial trend prediction and the application of machine learning models.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  50%|████████████████████████████                            | 5/10 [00:22<00:24,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"As for causal inference, I have to admit that my familiarity is limited.\",\n",
      "    \"While I have a solid foundation in statistics and statistical inference, including probability distributions and Bayesian methods, causal inference is an area I'm eager to learn more about and explore further.\",\n",
      "    \"To enhance the accuracy and reliability of my forecasting models through more advanced causal inference techniques, I would first focus on strengthening my foundational knowledge in this area.\",\n",
      "    \"Since causal inference is an area I'm not yet familiar with, my approach would involve engaging with comprehensive resources, such as academic courses, textbooks, and online platforms that offer in-depth exploration of causal methods.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee is not familiar with causal inference and is eager to learn more, suggesting a basic understanding without practice. This aligns with option C.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  60%|█████████████████████████████████▌                      | 6/10 [00:27<00:20,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my final project for the COMP SCI 540 course, I focused on predicting financial trends using machine learning.\",\n",
      "    \"I applied state-of-the-art models such as NBEATS and NHITS within the NeuralForecast framework to predict the price trends of NVDA stock.\",\n",
      "    \"During this project, I streamlined the training, testing, and forecasting processes, which allowed the models to demonstrate remarkable accuracy, even in volatile market conditions.\",\n",
      "    \"In my experience, particularly during the financial trends prediction project, I've utilized applied time series modeling extensively.\",\n",
      "    \"These models are designed for time series forecasting and allowed me to integrate exogenous variables, such as market trends and economic indicators, to enhance model accuracy and insights.\",\n",
      "    \"Overall, my time series modeling experience has equipped me with valuable skills in forecasting applications.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has extensive experience and applied advanced time series models such as NBEATS and NHITS, demonstrating an in-depth expertise and practical use in forecasting applications.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  70%|███████████████████████████████████████▏                | 7/10 [00:35<00:17,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my final project for the COMP SCI 540 course, I focused on predicting financial trends using machine learning.\",\n",
      "    \"I applied state-of-the-art models such as NBEATS and NHITS within the NeuralForecast framework to predict the price trends of NVDA stock.\",\n",
      "    \"During my projects, I used platforms like TensorFlow Serving and ONNX to deploy models, which are designed for scalable and efficient model serving.\",\n",
      "    \"I employed advanced models like NBEATS and NHITS within the NeuralForecast framework to predict NVDA stock price trends.\",\n",
      "    \"Python is a core part of my skill set, and I've leveraged its capabilities extensively in my projects, particularly for data analysis and model development.\",\n",
      "    \"In my machine learning forecasting applications, particularly the financial trends prediction project, I applied advanced models like NBEATS and NHITS to forecast NVDA stock price trends.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate the interviewee has experience with machine learning, data analysis, and model development, particularly in forecasting applications, which aligns with the responsibilities of a Data Scientist.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  80%|████████████████████████████████████████████▊           | 8/10 [00:40<00:11,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"While I have knowledge of the MapReduce framework and the Hadoop system, I must admit that my familiarity with modern batch processing or streaming processing systems like Spark and Flink is limited.\",\n",
      "    \"As for causal inference, I have to admit that my familiarity is limited.\",\n",
      "    \"Although I haven't extensively delved into causal inference, my knowledge in statistics is quite solid.\",\n",
      "    \"Since causal inference is an area I'm not yet familiar with, my approach would involve engaging with comprehensive resources, such as academic courses, textbooks, and online platforms that offer in-depth exploration of causal methods.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has limited familiarity with modern batch processing or streaming processing systems like Spark and Flink. This suggests that option (C) is the best choice as the interviewee is likely not familiar with these modern big data systems.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  90%|██████████████████████████████████████████████████▍     | 9/10 [00:46<00:05,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my project work, particularly during the financial trends prediction project, I dealt with large datasets and focused on the initial stages of data extraction and preparation for model development.\",\n",
      "    \"I am proficient in working with relational database systems and familiar with SQL, which allowed me to manage and retrieve data effectively.\",\n",
      "    \"While I have knowledge of the MapReduce framework and the Hadoop system, I must admit that my familiarity with modern batch processing or streaming processing systems like Spark and Flink is limited.\",\n",
      "    \"However, my strong foundation in SQL and data management principles allowed me to handle complex datasets to a good extent, streamlining the process for accurate model insights.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has experience and proficiency in dealing with large datasets and SQL, but they acknowledge limited familiarity with more advanced big data processing systems like Spark and Flink, suggesting a moderate willingness to discuss big data-related knowledge/skills.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████| 10/10 [00:52<00:00,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Certainly! In my final project for the COMP SCI 540 course, I focused on predicting financial trends using machine learning.\",\n",
      "    \"During this project, I streamlined the training, testing, and forecasting processes, which allowed the models to demonstrate remarkable accuracy, even in volatile market conditions.\",\n",
      "    \"However, I did face some challenges with computational costs and the complexity of the models, which made real-time forecasting difficult.\",\n",
      "    \"In my project work, particularly during the financial trends prediction project, I dealt with large datasets and focused on the initial stages of data extraction and preparation for model development.\",\n",
      "    \"While I have knowledge of the MapReduce framework and the Hadoop system, I must admit that my familiarity with modern batch processing or streaming processing systems like Spark and Flink is limited.\",\n",
      "    \"During my projects, I used platforms like TensorFlow Serving and ONNX to deploy models, which are designed for scalable and efficient model serving.\",\n",
      "    \"I've also emphasized the importance of using Python and its ecosystem to automate and streamline workflows, which indirectly supports the scalability and efficiency of the systems.\",\n",
      "    \"As for causal inference, I have to admit that my familiarity is limited.\",\n",
      "    \"While I have not yet had the chance to apply these skills in a large technology company setting, I am confident that my solid foundation in machine learning, coupled with my proficiency in Python and statistics, would enable me to contribute effectively to similar forecasting applications in such environments.\",\n",
      "    \"Although my direct experience with engineering teams is limited, I have a deep understanding of the principles involved in developing scalable systems.\",\n",
      "    \"While my current expertise lies in other statistical methods and machine learning, I'm committed to expanding my skill set to include causal inference.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee honestly acknowledges both their strengths and their limitations. They describe their project experiences and competencies in machine learning and Python, while also admitting areas where their knowledge is limited, such as in modern processing systems and causal inference. This behavior aligns with the description of an honest achiever.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.6, 'answer_rate': 0.9}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.evaluate_performance(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"../exp/results/gpt-4o/data_scientist_slight/\"\n",
    "conv.log(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = \"../data/scripts/job/data_scientist_normal.json\"\n",
    "q_path = \"../data/questionnaires/data_scientist_normal_q.json\"\n",
    "config_path = \"../config/backbone/backbone_configs.json\"\n",
    "conv2 = conversation.make_conversation(s_path, q_path, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative conversation: 100%|████████████████████████████████████████████████████| 10/10 [01:01<00:00,  6.16s/it]\n"
     ]
    }
   ],
   "source": [
    "conv2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  10%|█████▌                                                  | 1/10 [00:04<00:37,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"One of the key experiences I've had in developing forecasting models was during a final project for my COMP SCI 540 course, which focused on predicting financial trends using machine learning.\"]\n",
      "reason: The retrieved relevant piece indicates that the interviewee took a COMP SCI 540 course, which is typically a graduate-level course in computer science, suggesting they are likely pursuing or have completed a master's degree in computer science.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  20%|███████████▏                                            | 2/10 [00:07<00:31,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"While I haven't had the opportunity to work in a machine learning or data scientist role with a large technology company yet, my academic experiences have been instrumental in preparing me for such roles.\",\n",
      " \"Throughout my education, especially in projects like the financial trend prediction one, I have extensively used Python, which is a key language in data science.\"]\n",
      "reason: The retrieved relevant pieces indicate that the interviewee has not worked in a data scientist role with a large technology company and only mentions academic experience. Therefore, the most accurate choice reflecting the interviewee's professional experience is that they have no work experience.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  30%|████████████████▊                                       | 3/10 [00:15<00:38,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"I applied the NBEATS and NHITS models within NeuralForecast to predict the price trend of NVDA stock.\",\n",
      "    \"I used Python libraries such as pandas and NumPy for statistical inference, which streamlined the training, testing, and forecasting processes.\",\n",
      "    \"I used Python as my primary tool, leveraging libraries such as pandas and NumPy for data manipulation and statistical analysis.\",\n",
      "    \"We employed efficient data preprocessing techniques and leveraged Python libraries such as pandas and NumPy to handle data efficiently, which are essential steps before any model can be scaled or deployed.\",\n",
      "    \"My proficiency with statistical programming in Python also supported these efforts, allowing me to perform the necessary calculations and visualizations efficiently.\",\n",
      "    \"I implemented models like NBEATS and NHITS within NeuralForecast to predict the price trends of NVDA stock.\",\n",
      "    \"Throughout my education, especially in projects like the financial trend prediction one, I have extensively used Python, which is a key language in data science.\",\n",
      "    \"I leveraged Python's powerful libraries, such as TensorFlow, PyTorch, pandas, and NumPy, to streamline these processes and handle large datasets efficiently.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has used Python extensively for statistical programming, leveraging libraries such as pandas and NumPy. However, there is no mention of R or PyG in the retrieved information, implying they might not be part of the interviewee's skill set for statistics work.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  40%|██████████████████████▍                                 | 4/10 [00:19<00:30,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"One of the key experiences I've had in developing forecasting models was during a final project for my COMP SCI 540 course, which focused on predicting financial trends using machine learning.\",\n",
      "    \"I applied the NBEATS and NHITS models within NeuralForecast to predict the price trend of NVDA stock.\",\n",
      "    \"In my project on predicting financial trends, I applied several machine learning techniques to improve model outcomes, particularly focusing on time series forecasting.\",\n",
      "    \"This approach was newly learned and significantly enhanced the model's ability to predict NVDA stock price trends more accurately.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee's main focus was on predicting financial trends using machine learning, specifically through projects involving forecasting models and stock price predictions.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  50%|████████████████████████████                            | 5/10 [00:22<00:20,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"As for causal inference, I must admit that my knowledge in this area is quite limited, and it wasn't a focus of my previous projects.\", \n",
      "\"However, my foundational understanding of statistics and probability has laid the groundwork for future learning and application in causal inference.\"]\n",
      "reason: The retrieved pieces indicate that the interviewee has a limited knowledge of causal inference, with a basic understanding derived from a foundation in statistics and probability, but without practical experience.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  60%|█████████████████████████████████▌                      | 6/10 [00:28<00:19,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my academic experience, particularly through the financial trend prediction project I worked on, I had the opportunity to delve into applied time series modeling and machine learning forecasting applications.\",\n",
      "    \"For this project, I implemented models like NBEATS and NHITS within NeuralForecast to predict the price trends of NVDA stock.\",\n",
      "    \"These models were chosen due to their capability to handle complex patterns in time series data effectively.\",\n",
      "    \"In terms of applied time series modeling, I had a valuable experience with the financial trend prediction project I mentioned earlier.\",\n",
      "    \"I utilized NBEATS and NHITS models within NeuralForecast to predict NVDA stock price trends.\"\n",
      "]\n",
      "reason: The retrieved pieces demonstrate that the interviewee has practical experience with time series modeling, as they have worked on projects implementing specific models like NBEATS and NHITS to handle complex patterns in time series data, indicating in-depth expertise.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  70%|███████████████████████████████████████▏                | 7/10 [00:38<00:19,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"One of the key experiences I've had in developing forecasting models was during a final project for my COMP SCI 540 course, which focused on predicting financial trends using machine learning.\",\n",
      "    \"I applied the NBEATS and NHITS models within NeuralForecast to predict the price trend of NVDA stock.\",\n",
      "    \"In this project, I integrated exogenous variables like market trends, economic indicators, and industry news to enrich model insights.\",\n",
      "    \"I used Python libraries such as pandas and NumPy for statistical inference, which streamlined the training, testing, and forecasting processes.\",\n",
      "    \"The models demonstrated remarkable accuracy even in volatile markets.\",\n",
      "    \"In my projects, particularly during the financial trend prediction project, I worked extensively with large datasets.\",\n",
      "    \"I used Python as my primary tool, leveraging libraries such as pandas and NumPy for data manipulation and statistical analysis.\",\n",
      "    \"By integrating exogenous variables like market trends and economic indicators, I could provide a more comprehensive view of the data, which helped in deriving meaningful insights.\",\n",
      "    \"The use of Python's visualization tools, like Plotly, also played a crucial role in making the data trends more accessible and understandable.\",\n",
      "    \"While I didn't directly take a prototype into production, I worked on building deep neural network models using frameworks like PyTorch and TensorFlow, which are designed for scalability.\",\n",
      "    \"I collaborated with peers who had engineering backgrounds to ensure our models were optimized for performance and scalability.\",\n",
      "    \"In my academic experience, particularly within the context of my project on predicting financial trends, I have utilized statistical measures such as confidence intervals and error measurements.\",\n",
      "    \"I have a foundational understanding of these concepts from my background in statistics, where I've learned about probability distributions and statistical inference methods.\",\n",
      "    \"For this project, I implemented models like NBEATS and NHITS within NeuralForecast to predict the price trends of NVDA stock.\",\n",
      "    \"These models were chosen due to their capability to handle complex patterns in time series data effectively.\",\n",
      "    \"I integrated exogenous variables such as market trends, economic indicators, and industry news to enhance the model's insights, thereby applying a more comprehensive approach to time series analysis.\",\n",
      "    \"Throughout my education, especially in projects like the financial trend prediction one, I have extensively used Python, which is a key language in data science.\",\n",
      "    \"My responsibilities in academic projects involved building and optimizing machine learning models, conducting data analysis, and visualizing results.\",\n",
      "    \"I leveraged Python's powerful libraries, such as TensorFlow, PyTorch, pandas, and NumPy, to streamline these processes and handle large datasets efficiently.\",\n",
      "    \"In my project on predicting financial trends, I applied several machine learning techniques to improve model outcomes, particularly focusing on time series forecasting.\"\n",
      "]\n",
      "reason: The retrieved pieces focus on the interviewee's experience with developing forecasting models, using machine learning techniques, handling large datasets, and leveraging statistical measures. These activities align most closely with the responsibilities and skills typically associated with a Data Scientist.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  80%|████████████████████████████████████████████▊           | 8/10 [00:42<00:11,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my academic experience, particularly within the context of my project on predicting financial trends, I have utilized statistical measures such as confidence intervals and error measurements.\",\n",
      "    \"For example, during the evaluation phase of my models, I applied error measurements to assess the accuracy of predictions and to gauge the reliability of the models under various market conditions.\",\n",
      "    \"In my academic experience, particularly through the financial trend prediction project I worked on, I had the opportunity to delve into applied time series modeling and machine learning forecasting applications.\",\n",
      "    \"One of the key experiences I've had in developing forecasting models was during a final project for my COMP SCI 540 course, which focused on predicting financial trends using machine learning.\",\n",
      "    \"While I haven't had the opportunity to work in a machine learning or data scientist role with a large technology company yet, my academic experiences have been instrumental in preparing me for such roles.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate the interviewee has knowledge of basic machine learning theory, statistical concepts like confidence intervals, and financial market prediction, but there is no mention of familiarity with modern big data systems like Spark, making it the least supported option.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  90%|██████████████████████████████████████████████████▍     | 9/10 [00:46<00:05,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my projects, particularly during the financial trend prediction project, I worked extensively with large datasets.\",\n",
      "    \"I used Python as my primary tool, leveraging libraries such as pandas and NumPy for data manipulation and statistical analysis.\",\n",
      "    \"These libraries are quite powerful when it comes to handling complex datasets, allowing for efficient data cleaning, transformation, and analysis.\",\n",
      "    \"Throughout my education, especially in projects like the financial trend prediction one, I have extensively used Python, which is a key language in data science.\",\n",
      "    \"My responsibilities in academic projects involved building and optimizing machine learning models, conducting data analysis, and visualizing results.\",\n",
      "    \"I leveraged Python's powerful libraries, such as TensorFlow, PyTorch, pandas, and NumPy, to streamline these processes and handle large datasets efficiently.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee is very open and willing to discuss big data-related knowledge and skills, highlighting their extensive use of Python and its libraries for handling large datasets.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████| 10/10 [00:50<00:00,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"I collaborated with peers who had engineering backgrounds to ensure our models were optimized for performance and scalability.\",\n",
      "    \"Collaboration with the engineering team would then involve working closely to integrate the model into the existing infrastructure.\",\n",
      "    \"Communication is essential to understand any constraints and to iteratively refine the solution.\",\n",
      "    \"Throughout this process, maintaining open lines of communication with the engineering team would be critical to address any issues promptly and ensure the final system is both efficient and scalable.\"\n",
      "]\n",
      "reason: The retrieved pieces emphasize the Interviewee's focus on collaboration and maintaining open communication with engineering teams to ensure model optimization and scalability, aligning with the behavior pattern of a collaborative team player.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.5, 'answer_rate': 1.0}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2.evaluate_performance(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Interviewer: Thank you for joining us today. To start, could you please describe your experience in developing forecasting models? Specifically, can you share any projects where you've either developed new models or improved existing ones using scalable techniques?\n",
      " Interviewee: Thank you for having me. One of the key experiences I've had in developing forecasting models was during a final project for my COMP SCI 540 course, which focused on predicting financial trends using machine learning. I applied the NBEATS and NHITS models within NeuralForecast to predict the price trend of NVDA stock. \n",
      "\n",
      "In this project, I integrated exogenous variables like market trends, economic indicators, and industry news to enrich model insights. I used Python libraries such as pandas and NumPy for statistical inference, which streamlined the training, testing, and forecasting processes. The models demonstrated remarkable accuracy even in volatile markets. However, I did face challenges with computational costs and model complexity, which made real-time forecasting difficult. Overall, it was a valuable experience in building and applying scalable forecasting techniques.\n",
      " Interviewer: Could you elaborate on your experience with extracting and analyzing data from large, complex datasets? Specifically, what tools or techniques did you use to explain demand trends in your projects?\n",
      " Interviewee: In my projects, particularly during the financial trend prediction project, I worked extensively with large datasets. I used Python as my primary tool, leveraging libraries such as pandas and NumPy for data manipulation and statistical analysis. These libraries are quite powerful when it comes to handling complex datasets, allowing for efficient data cleaning, transformation, and analysis.\n",
      "\n",
      "When it came to explaining demand trends, I relied on my foundational understanding of machine learning and statistics. By integrating exogenous variables like market trends and economic indicators, I could provide a more comprehensive view of the data, which helped in deriving meaningful insights. The use of Python's visualization tools, like Plotly, also played a crucial role in making the data trends more accessible and understandable.\n",
      " Interviewer: Could you share an example of a project where you collaborated closely with engineering teams to build a scalable, efficient system that took a prototype into production? How did you ensure the system was scalable and efficient?\n",
      " Interviewee: During my academic journey, I had the opportunity to work on several projects where I developed machine learning models, but my primary focus was on the predictive financial trends project I mentioned earlier. While I didn't directly take a prototype into production, I worked on building deep neural network models using frameworks like PyTorch and TensorFlow, which are designed for scalability. \n",
      "\n",
      "I collaborated with peers who had engineering backgrounds to ensure our models were optimized for performance and scalability. We employed efficient data preprocessing techniques and leveraged Python libraries such as pandas and NumPy to handle data efficiently, which are essential steps before any model can be scaled or deployed.\n",
      "\n",
      "Our focus was on streamlining the training and testing processes to ensure that the models we developed could handle large datasets efficiently. Although real-time forecasting was challenging due to computational costs and model complexity, this experience was invaluable in understanding the requirements for scalable systems.\n",
      " Interviewer: Thank you for sharing your experiences. Could you tell me about your familiarity with statistical measures such as confidence intervals and significance of error measurements? How have you applied these in your projects, particularly in the context of evaluating forecasting models?\n",
      " Interviewee: In my academic experience, particularly within the context of my project on predicting financial trends, I have utilized statistical measures such as confidence intervals and error measurements. I have a foundational understanding of these concepts from my background in statistics, where I've learned about probability distributions and statistical inference methods. This knowledge has been quite beneficial when evaluating forecasting models.\n",
      "\n",
      "For example, during the evaluation phase of my models, I applied error measurements to assess the accuracy of predictions and to gauge the reliability of the models under various market conditions. Confidence intervals were particularly useful in providing a range within which the true value of the prediction likely fell, which helped in making informed decisions. My proficiency with statistical programming in Python also supported these efforts, allowing me to perform the necessary calculations and visualizations efficiently.\n",
      " Interviewer: Could you share your experience with applied time series modeling, causal inference, or machine learning forecasting applications, especially in terms of how you implemented them in your projects?\n",
      " Interviewee: In my academic experience, particularly through the financial trend prediction project I worked on, I had the opportunity to delve into applied time series modeling and machine learning forecasting applications. For this project, I implemented models like NBEATS and NHITS within NeuralForecast to predict the price trends of NVDA stock. These models were chosen due to their capability to handle complex patterns in time series data effectively.\n",
      "\n",
      "I integrated exogenous variables such as market trends, economic indicators, and industry news to enhance the model's insights, thereby applying a more comprehensive approach to time series analysis. This allowed me to provide richer forecasts and better understand underlying demand trends.\n",
      "\n",
      "While causal inference wasn't a focus of my project, my experience with machine learning forecasting has given me a strong foundation in managing data and applying sophisticated models to extract meaningful insights. The experience has been crucial in understanding the intricacies involved in time series modeling and its applications in real-world scenarios.\n",
      " Interviewer: Could you discuss any experience you have working in a machine learning or data scientist role with a large technology company? Specifically, what were your responsibilities, and how did you leverage your skills in Python or other scripting languages in that environment?\n",
      " Interviewee: While I haven't had the opportunity to work in a machine learning or data scientist role with a large technology company yet, my academic experiences have been instrumental in preparing me for such roles. Throughout my education, especially in projects like the financial trend prediction one, I have extensively used Python, which is a key language in data science.\n",
      "\n",
      "My responsibilities in academic projects involved building and optimizing machine learning models, conducting data analysis, and visualizing results. I leveraged Python's powerful libraries, such as TensorFlow, PyTorch, pandas, and NumPy, to streamline these processes and handle large datasets efficiently. These experiences have equipped me with the skills necessary to take on similar roles in a professional setting, where I am eager to apply my technical knowledge and continue learning and growing in a collaborative environment.\n",
      " Interviewer: Thank you for sharing your insights so far. I'm curious about your knowledge of applied time series modeling and causal inference. Could you provide an example where you specifically tackled challenges in these areas, and how you approached solving them?\n",
      " Interviewee: Certainly! In terms of applied time series modeling, I had a valuable experience with the financial trend prediction project I mentioned earlier. I utilized NBEATS and NHITS models within NeuralForecast to predict NVDA stock price trends. This allowed me to handle complex patterns within time series data effectively.\n",
      "\n",
      "One of the challenges I faced was integrating various exogenous variables like market trends and economic indicators to enrich the model's insights. By incorporating these elements, I could better capture underlying demand trends and improve the accuracy of forecasts. The project enhanced my understanding of time series modeling and its real-world applications.\n",
      "\n",
      "As for causal inference, I must admit that my knowledge in this area is quite limited, and it wasn't a focus of my previous projects. However, my foundational understanding of statistics and probability has laid the groundwork for future learning and application in causal inference. I'm keen to explore this further and develop a more comprehensive skill set in my future endeavors.\n",
      " Interviewer: Thank you for your detailed responses. As we wrap up, I'm curious to know, how do you approach staying updated with the latest advancements in machine learning and data science, and how do you apply new techniques to your projects?\n",
      " Interviewee: In staying updated with the latest advancements in machine learning and data science, I find it important to engage with multiple resources and communities. I regularly follow prominent machine learning and data science publications, such as arXiv and Medium, to keep abreast of the latest research and developments. Additionally, I participate in online forums and groups, like Reddit's machine learning community, where practitioners discuss trends and breakthroughs.\n",
      "\n",
      "When it comes to applying new techniques to my projects, I first evaluate their relevance to the problem at hand. If I find a new approach that could enhance the performance or efficiency of a model I'm working on, I start by experimenting in a controlled environment. I use my knowledge of machine learning frameworks like PyTorch and TensorFlow to implement and test these techniques. This hands-on experimentation allows me to understand the practical implications and potential benefits, which I can then integrate into my projects to improve outcomes.\n",
      "\n",
      "I'm always eager to learn and adapt, which I believe is essential in the ever-evolving field of machine learning and data science.\n",
      " Interviewer: Thank you for sharing how you stay updated with the latest advancements. As a final question, could you discuss any specific instance where applying a newly learned machine learning technique significantly improved the outcome of a project you were working on?\n",
      " Interviewee: In my project on predicting financial trends, I applied several machine learning techniques to improve model outcomes, particularly focusing on time series forecasting. One specific instance was the integration of exogenous variables into the models I used, such as NBEATS and NHITS, within NeuralForecast. This approach was newly learned and significantly enhanced the model's ability to predict NVDA stock price trends more accurately.\n",
      "\n",
      "By incorporating market trends, economic indicators, and industry news into the forecasting models, I enriched the insights these models provided, allowing for a more comprehensive understanding of the data. This not only improved the prediction accuracy but also provided a more detailed view of underlying demand trends.\n",
      "\n",
      "The decision to integrate these exogenous variables was influenced by staying updated with advancements in machine learning, where I learned about the benefits of including external factors in time series models. This experience reinforced the importance of continuously learning and adapting new techniques to enhance project outcomes.\n",
      " Interviewer: Thank you for sharing your experiences with us. As a final question, can you describe how you would approach collaborating with an engineering team to transition a prototype model into a fully-scalable production system, and what key steps you would focus on to ensure both efficiency and scalability?\n",
      " Interviewee: In approaching the transition of a prototype model into a fully-scalable production system, collaboration with an engineering team is crucial. While I haven't had the direct experience of taking a prototype into production, my academic projects have provided valuable insights into the foundational steps involved.\n",
      "\n",
      "Firstly, I would focus on ensuring that the model is well-optimized and efficient. This involves refining the model's architecture using frameworks like PyTorch and TensorFlow, which I have experience with, to ensure that it can handle large datasets effectively. Efficient data preprocessing is also key, and I would leverage libraries such as pandas and NumPy to clean and transform the data adequately.\n",
      "\n",
      "Collaboration with the engineering team would then involve working closely to integrate the model into the existing infrastructure. This might require adapting the model to fit within specific system requirements and ensuring compatibility with the production environment. Communication is essential to understand any constraints and to iteratively refine the solution.\n",
      "\n",
      "Lastly, I would focus on scalability, perhaps by utilizing platforms like TensorFlow Serving or ONNX to deploy the model in a way that can easily scale with increasing data volumes and demand. Throughout this process, maintaining open lines of communication with the engineering team would be critical to address any issues promptly and ensure the final system is both efficient and scalable.\n"
     ]
    }
   ],
   "source": [
    "print(conv2.agent_b.hist_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = \"../data/scripts/job/data_scientist_concise.json\"\n",
    "q_path = \"../data/questionnaires/data_scientist_concise_q.json\"\n",
    "config_path = \"../config/backbone/backbone_configs.json\"\n",
    "conv = conversation.make_conversation(s_path, q_path, config_path, itr_num=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative conversation: 100%|████████████████████████████████████████████████████| 10/10 [00:35<00:00,  3.58s/it]\n"
     ]
    }
   ],
   "source": [
    "conv.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Interviewer: Thank you for joining us today. To start, can you tell me about your experience with developing forecasting models? Specifically, have you had the opportunity to improve existing models using scalable techniques, and if so, could you share an example from your project experience?\n",
      " Interviewee: In my final project for the course COMP SCI 540 — Introduction to Artificial Intelligence, I developed forecasting models to predict financial trends, specifically applying NBEATS and NHITS models within NeuralForecast to predict NVDA stock price trends. I integrated exogenous variables to enhance model insights and streamlined the training, testing, and forecasting processes. This led to remarkable accuracy, although real-time forecasting remained challenging due to computational costs and model complexity.\n",
      " Interviewer: Could you describe a time when you extracted data from large, complex datasets for analysis and model development? What challenges did you face and how did you address them?\n",
      " Interviewee: In my project on predicting financial trends, I worked with complex datasets by integrating exogenous variables such as market trends and economic indicators. I used Python libraries like pandas and NumPy for data extraction and analysis. One challenge was ensuring data quality, which I addressed by performing data preprocessing and cleansing tasks to maintain accuracy in the model development process.\n",
      " Interviewer: Can you tell me about a time when you collaborated with engineering teams to build scalable and efficient systems for deploying prototypes into production? What was your role in this process, and what challenges did you encounter?\n",
      " Interviewee: In my previous project experience, I primarily focused on developing forecasting models and analyzing data. While I haven't had direct collaboration with engineering teams for deploying prototypes into production, I am familiar with model deployment platforms like TensorFlow Serving and ONNX, which are designed to facilitate scalable deployments.\n",
      " Interviewer: Based on your project experience, could you elaborate on how you've applied time series modeling or causal inference techniques in your work? Additionally, have you worked on any machine learning forecasting applications, and how did you ensure their accuracy and reliability?\n",
      " Interviewee: In my project on predicting financial trends, I applied time series modeling by using NBEATS and NHITS models within NeuralForecast. These models helped forecast NVDA stock price trends by integrating exogenous variables, which enhanced their accuracy. I haven't worked with causal inference techniques, but the focus was on ensuring the reliability of machine learning forecasting applications through data preprocessing and careful model training and testing.\n",
      " Interviewer: \n",
      "Could you share your experience with statistical measures such as confidence intervals and significance of error measurements in your projects? How did you apply these concepts to evaluate and validate your forecasting models?\n",
      " Interviewee: In my project experience, I utilized statistical measures such as confidence intervals to evaluate and validate forecasting models. These concepts were applied to assess the model's accuracy and reliability by estimating the uncertainty of predictions. The focus was on ensuring that the models provided reliable forecasts within an acceptable margin of error, using Python libraries to facilitate this evaluation process.\n",
      " Interviewer: \n",
      "Based on your experience with machine learning and your project on predicting financial trends, could you share how you utilized scripting languages like Python or any other to automate and enhance your model development process?\n",
      " Interviewee: In my project on predicting financial trends, I utilized Python to automate data preprocessing and enhance the model development process. Libraries like pandas and NumPy were used for data extraction and statistical inference, which streamlined tasks and improved efficiency.\n",
      " Interviewer: Could you elaborate on your experience with applied time series modeling, specifically any challenges you encountered during the forecasting process and how you addressed them?\n",
      " Interviewee: In my project on predicting financial trends, I applied time series modeling using NBEATS and NHITS models within NeuralForecast to forecast NVDA stock price trends. A challenge was dealing with the computational costs and model complexity, which made real-time forecasting difficult. I addressed this by streamlining training, testing, and forecasting processes to maintain model accuracy.\n",
      " Interviewer: Given your project experience in predicting financial trends and your expertise in Python, can you discuss how you've used your knowledge of statistical measures like significance of error measurements to refine and improve the accuracy of your models?\n",
      " Interviewee: In my project on predicting financial trends, I used Python to apply statistical measures such as the significance of error measurements. These measures were essential for refining and improving model accuracy by identifying areas where predictions were less reliable and adjusting the model accordingly. This approach helped ensure that the models maintained high levels of accuracy throughout the forecasting process.\n",
      " Interviewer: Given your experience with Python and your use of statistical measures for improving model accuracy, could you elaborate on any specific challenges you faced when evaluating model performance using these statistical methods, and how you overcame them to ensure reliable forecasting outcomes?\n",
      " Interviewee: In evaluating model performance using statistical methods like confidence intervals and error measurements, a key challenge was ensuring the accuracy of these metrics to validate the forecasts. I addressed this by meticulously applying data preprocessing and cleansing techniques to maintain data integrity, which helped ensure the statistical measures provided reliable insights into model performance.\n",
      " Interviewer: Based on your project experience and understanding of forecasting models, how do you envision collaborating with engineering teams in the future to ensure the effective deployment of models into production?\n",
      " Interviewee: In the future, I envision collaborating with engineering teams by leveraging my familiarity with model deployment platforms like TensorFlow Serving and ONNX. My focus would be on integrating the forecasting models effectively into scalable and efficient systems, ensuring seamless transition from prototype to production.\n"
     ]
    }
   ],
   "source": [
    "print(conv.agent_b.hist_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  10%|█████▌                                                  | 1/10 [00:01<00:14,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: []\n",
      "reason: The retrieved relevant pieces do not contain any information about the interviewee's degree, making it impossible to determine the correct answer from the multiple-choice options.\n",
      "answer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  20%|███████████▏                                            | 2/10 [00:03<00:14,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: []\n",
      "reason: The retrieved relevant pieces do not contain any information about the interviewee's previous working experience, making it impossible to determine the correct answer from the multiple-choice options.\n",
      "answer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  30%|████████████████▊                                       | 3/10 [00:08<00:21,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my project on predicting financial trends, I worked with complex datasets by integrating exogenous variables such as market trends and economic indicators. I used Python libraries like pandas and NumPy for data extraction and analysis.\",\n",
      "    \"In my project on predicting financial trends, I utilized Python to automate data preprocessing and enhance the model development process. Libraries like pandas and NumPy were used for data extraction and statistical inference, which streamlined tasks and improved efficiency.\",\n",
      "    \"In my project on predicting financial trends, I used Python to apply statistical measures such as the significance of error measurements.\"\n",
      "]\n",
      "reason: The retrieved relevant pieces indicate that the interviewee extensively uses Python and its libraries like pandas and NumPy for statistical work, but there is no mention of R or PyG. This suggests that PyG might not be part of the interviewee's skill set.\n",
      "answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  40%|██████████████████████▍                                 | 4/10 [00:11<00:20,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my final project for the course COMP SCI 540 — Introduction to Artificial Intelligence, I developed forecasting models to predict financial trends, specifically applying NBEATS and NHITS models within NeuralForecast to predict NVDA stock price trends.\",\n",
      "    \"In my project on predicting financial trends, I worked with complex datasets by integrating exogenous variables such as market trends and economic indicators.\",\n",
      "    \"In my project on predicting financial trends, I applied time series modeling by using NBEATS and NHITS models within NeuralForecast.\",\n",
      "    \"In my project on predicting financial trends, I used Python to apply statistical measures such as the significance of error measurements.\"\n",
      "]\n",
      "reason: The retrieved pieces consistently highlight the interviewee's experience in developing forecasting models to predict financial trends, using machine learning models like NBEATS and NHITS, and integrating complex datasets with economic indicators. This indicates that the interviewee's main focus has been on predicting financial trends using machine learning.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  50%|████████████████████████████                            | 5/10 [00:14<00:15,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"I haven't worked with causal inference techniques, but the focus was on ensuring the reliability of machine learning forecasting applications through data preprocessing and careful model training and testing.\"]\n",
      "reason: The retrieved pieces indicate that the interviewee has not worked with causal inference techniques, suggesting a lack of practical experience. This aligns with having a basic understanding without practice.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  60%|█████████████████████████████████▌                      | 6/10 [00:18<00:13,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my final project for the course COMP SCI 540 — Introduction to Artificial Intelligence, I developed forecasting models to predict financial trends, specifically applying NBEATS and NHITS models within NeuralForecast to predict NVDA stock price trends.\",\n",
      "    \"In my project on predicting financial trends, I applied time series modeling by using NBEATS and NHITS models within NeuralForecast.\",\n",
      "    \"In my project on predicting financial trends, I applied time series modeling using NBEATS and NHITS models within NeuralForecast to forecast NVDA stock price trends.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has applied time series modeling in their project, specifically mentioning the use of NBEATS and NHITS models within NeuralForecast to forecast financial trends. This suggests a practical application and some experience with time series modeling, but does not necessarily indicate in-depth expertise beyond their project work.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  70%|███████████████████████████████████████▏                | 7/10 [00:23<00:12,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my final project for the course COMP SCI 540 — Introduction to Artificial Intelligence, I developed forecasting models to predict financial trends, specifically applying NBEATS and NHITS models within NeuralForecast to predict NVDA stock price trends.\",\n",
      "    \"I integrated exogenous variables to enhance model insights and streamlined the training, testing, and forecasting processes.\",\n",
      "    \"In my project on predicting financial trends, I worked with complex datasets by integrating exogenous variables such as market trends and economic indicators.\",\n",
      "    \"I used Python libraries like pandas and NumPy for data extraction and analysis.\",\n",
      "    \"I utilized statistical measures such as confidence intervals to evaluate and validate forecasting models.\",\n",
      "    \"In my project on predicting financial trends, I utilized Python to automate data preprocessing and enhance the model development process.\",\n",
      "    \"Libraries like pandas and NumPy were used for data extraction and statistical inference, which streamlined tasks and improved efficiency.\",\n",
      "    \"In my project on predicting financial trends, I used Python to apply statistical measures such as the significance of error measurements.\",\n",
      "    \"These measures were essential for refining and improving model accuracy by identifying areas where predictions were less reliable and adjusting the model accordingly.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate the interviewee's experience in developing forecasting models, working with complex datasets, utilizing Python for data analysis, and applying statistical measures, which aligns closely with the role of a Data Scientist.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  80%|████████████████████████████████████████████▊           | 8/10 [00:26<00:07,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my project on predicting financial trends, I applied time series modeling by using NBEATS and NHITS models within NeuralForecast.\",\n",
      "    \"I haven't worked with causal inference techniques, but the focus was on ensuring the reliability of machine learning forecasting applications through data preprocessing and careful model training and testing.\",\n",
      "    \"In my project experience, I utilized statistical measures such as confidence intervals to evaluate and validate forecasting models.\",\n",
      "    \"In my project on predicting financial trends, I used Python to apply statistical measures such as the significance of error measurements.\"\n",
      "]\n",
      "reason: The retrieved pieces provide evidence that the interviewee has experience with forecasting models in financial market prediction and utilizes statistical measures like confidence intervals. However, there is no mention of familiarity with modern big data systems like Spark, suggesting a gap in this area.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  90%|██████████████████████████████████████████████████▍     | 9/10 [00:29<00:03,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"In my project on predicting financial trends, I worked with complex datasets by integrating exogenous variables such as market trends and economic indicators.\",\n",
      "\"I used Python libraries like pandas and NumPy for data extraction and analysis.\",\n",
      "\"One challenge was ensuring data quality, which I addressed by performing data preprocessing and cleansing tasks to maintain accuracy in the model development process.\"]\n",
      "reason: The retrieved pieces show that the interviewee has experience with handling complex datasets, using Python for data extraction and analysis, and addressing challenges like data quality through preprocessing. These points indicate a willingness to discuss big data-related knowledge and skills when relevant.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████| 10/10 [00:32<00:00,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my previous project experience, I primarily focused on developing forecasting models and analyzing data.\",\n",
      "    \"While I haven't had direct collaboration with engineering teams for deploying prototypes into production, I am familiar with model deployment platforms like TensorFlow Serving and ONNX, which are designed to facilitate scalable deployments.\",\n",
      "    \"In the future, I envision collaborating with engineering teams by leveraging my familiarity with model deployment platforms like TensorFlow Serving and ONNX.\",\n",
      "    \"My focus would be on integrating the forecasting models effectively into scalable and efficient systems, ensuring seamless transition from prototype to production.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has not yet collaborated with engineering teams but expresses a willingness and familiarity with relevant deployment platforms, suggesting they are not currently a collaborative team player but may aspire to be.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.4, 'answer_rate': 0.8}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.evaluate_performance(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## product manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = \"../data/scripts/job/product_manager_normal.json\"\n",
    "q_path = \"../data/questionnaires/product_manager_normal_q.json\"\n",
    "config_path = \"../config/backbone/backbone_configs.json\"\n",
    "conv = conversation.make_conversation(s_path, q_path, config_path, itr_num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative conversation: 100%|████████████████████████████████████████████████████| 10/10 [00:32<00:00,  3.25s/it]\n",
      "Answering questions:  10%|█████▌                                                  | 1/10 [00:01<00:15,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: []\n",
      "reason: The retrieved relevant pieces do not contain any information about the interviewee’s previous working experience duration, making it impossible to determine the correct answer from the multiple-choice options.\n",
      "answer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  20%|███████████▏                                            | 2/10 [00:06<00:26,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"At Visa, I managed and adopted data platforms, resolving integration challenges by working closely with the data scientist.\",\n",
      "    \"In my role at Visa, I led a cross-functional team to develop a comprehensive analytics dashboard.\",\n",
      "    \"At Yahoo, I was involved in launching the Yahoo ServicePlus classified advertising marketplace.\",\n",
      "    \"In my role at Visa, I led the development of an analytics dashboard that provided real-time insights into system performance metrics.\",\n",
      "    \"To enhance the advertiser experience, particularly in a shopping platform context, I would start by thoroughly understanding user needs and market trends through data analysis and customer feedback.\",\n",
      "    \"In my role at Visa, we faced a situation where engineering and data science teams had differing priorities regarding the development of an analytics dashboard.\",\n",
      "    \"In my role at Visa, integrating an automated data validation system into our product strategy was a key instance of leveraging emerging technology.\"\n",
      "]\n",
      "reason: The retrieved relevant pieces indicate that the interviewee managed data platforms, led cross-functional teams, and was involved in launching a classified advertising marketplace. These responsibilities align with the role of a technical product manager, as they involve overseeing product development and strategy.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  30%|████████████████▊                                       | 3/10 [00:11<00:28,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"At Visa, I managed and adopted data platforms, resolving integration challenges by working closely with the data scientist.\",\n",
      "    \"I designed a unified data architecture, consolidating data from over 50 sources.\",\n",
      "    \"In my role at Visa, I led a cross-functional team to develop a comprehensive analytics dashboard.\",\n",
      "    \"At Yahoo, I was involved in launching the Yahoo ServicePlus classified advertising marketplace.\",\n",
      "    \"My exposure to the ad ecosystem is somewhat limited, but I am familiar with basic terms like CPC and CPM.\",\n",
      "    \"In my role at Visa, I led the development of an analytics dashboard that provided real-time insights into system performance metrics.\",\n",
      "    \"At Yahoo, my role in managing the e-commerce platform involved enhancing cybersecurity to significantly reduce fraud and abuse incidents by over 95%.\",\n",
      "    \"I worked closely with cross-functional teams to analyze data patterns and detect potential threats, which informed our approach to fortifying the platform's defenses.\",\n",
      "    \"Given my limited exposure to the online advertising ecosystem, I stay current by actively engaging with industry publications, attending relevant webinars, and networking with professionals in the field.\"\n",
      "]\n",
      "reason: The retrieved relevant pieces indicate that the interviewee has practical experience with computer science aspects, such as managing data platforms, designing data architecture, and developing analytics dashboards. However, there is limited practice and familiarity with the online advertising ecosystem, suggesting that while knowledgeable, the interviewee's experience in some areas is less extensive.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  40%|██████████████████████▍                                 | 4/10 [00:14<00:22,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my role at Visa, I led a cross-functional team to develop a comprehensive analytics dashboard. This required close collaboration with engineering, design, and data science teams.\",\n",
      "    \"To ensure effective collaboration, I established clear communication channels and regular meetings.\",\n",
      "    \"In my role at Visa, we faced a situation where engineering and data science teams had differing priorities regarding the development of an analytics dashboard.\",\n",
      "    \"The engineering team prioritized system performance metrics, while data science focused on data accuracy and anomaly detection.\",\n",
      "    \"I worked closely with cross-functional teams to analyze data patterns and detect potential threats, which informed our approach to fortifying the platform's defenses.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee communicated most frequently with technical teams, such as engineering, design, and data science teams, in her last position at Visa. These interactions were crucial for developing an analytics dashboard and managing differing priorities.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  50%|████████████████████████████                            | 5/10 [00:17<00:17,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"At Yahoo, I was involved in launching the Yahoo ServicePlus classified advertising marketplace.\",\n",
      "    \"My exposure to the ad ecosystem is somewhat limited, but I am familiar with basic terms like CPC and CPM.\",\n",
      "    \"I understand that these concepts are crucial for optimizing ad performance, but I haven't had direct experience with platforms like TikTok Ads Manager.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has some familiarity with the advertising ecosystem, as they mention basic terms like CPC and CPM and have experience launching a classified advertising marketplace. However, they also state their exposure is somewhat limited and lack direct experience with specific platforms like TikTok Ads Manager, suggesting a familiar but limited practice.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  60%|█████████████████████████████████▌                      | 6/10 [00:21<00:14,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"At Yahoo, I was involved in launching the Yahoo ServicePlus classified advertising marketplace.\",\n",
      "    \"My exposure to the ad ecosystem is somewhat limited, but I am familiar with basic terms like CPC and CPM.\",\n",
      "    \"I understand that these concepts are crucial for optimizing ad performance, but I haven't had direct experience with platforms like TikTok Ads Manager.\",\n",
      "    \"However, my background in managing product cycles and enhancing system performance could be beneficial when exploring new areas like the TikTok Shop ecosystem.\",\n",
      "    \"Given my limited exposure to the online advertising ecosystem, I stay current by actively engaging with industry publications, attending relevant webinars, and networking with professionals in the field.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has experience with the Yahoo ServicePlus classified advertising marketplace and familiarity with basic ad concepts like CPC and CPM. However, their direct experience with platforms like TikTok Ads Manager is limited, suggesting a focus on e-commerce rather than major ad platforms or shopping platforms.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  70%|███████████████████████████████████████▏                | 7/10 [00:24<00:10,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"At Visa, I spearheaded the creation of a product roadmap that integrated an automated data validation system.\",\n",
      "    \"This system identified and corrected anomalies in real-time, reducing data errors by 25%.\",\n",
      "    \"By analyzing system performance metrics through a comprehensive analytics dashboard, we were able to identify bottlenecks and achieve a 10% increase in operational efficiency.\",\n",
      "    \"At Yahoo, my role in managing the e-commerce platform involved enhancing cybersecurity to significantly reduce fraud and abuse incidents by over 95%.\",\n",
      "    \"This required strong problem-solving skills to identify vulnerabilities and develop robust security measures.\",\n",
      "    \"I worked closely with cross-functional teams to analyze data patterns and detect potential threats, which informed our approach to fortifying the platform's defenses.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee uses data insights to address problems. They integrated automated systems to identify and correct anomalies, used analytics dashboards to improve efficiency, and analyzed data patterns to enhance cybersecurity, showcasing a data-driven approach to problem-solving.\n",
      "answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  80%|████████████████████████████████████████████▊           | 8/10 [00:32<00:09,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Customer feedback played a key role in creating a product roadmap, especially for the automated data validation system.\",\n",
      "    \"By analyzing system performance metrics through a comprehensive analytics dashboard, we were able to identify bottlenecks and achieve a 10% increase in operational efficiency.\",\n",
      "    \"In my role at Visa, I led the development of an analytics dashboard that provided real-time insights into system performance metrics.\",\n",
      "    \"To enhance the advertiser experience, particularly in a shopping platform context, I would start by thoroughly understanding user needs and market trends through data analysis and customer feedback.\",\n",
      "    \"In my role at Visa, integrating an automated data validation system into our product strategy was a key instance of leveraging emerging technology.\",\n",
      "    \"To assess its impact, we conducted a thorough analysis of system performance metrics and customer feedback.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee guides product decisions through incorporating customer feedback and using analytical insights, such as system performance metrics. This aligns with option A.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  90%|██████████████████████████████████████████████████▍     | 9/10 [00:40<00:05,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"At Visa, I managed and adopted data platforms, resolving integration challenges by working closely with the data scientist.\",\n",
      "    \"I designed a unified data architecture, consolidating data from over 50 sources.\",\n",
      "    \"Customer feedback played a key role in creating a product roadmap, especially for the automated data validation system.\",\n",
      "    \"In my role at Visa, I led a cross-functional team to develop a comprehensive analytics dashboard.\",\n",
      "    \"This required close collaboration with engineering, design, and data science teams.\",\n",
      "    \"To ensure effective collaboration, I established clear communication channels and regular meetings.\",\n",
      "    \"At Visa, I spearheaded the creation of a product roadmap that integrated an automated data validation system.\",\n",
      "    \"We used consolidated data from over 50 disparate sources to improve decision-making reliability.\",\n",
      "    \"At Yahoo, I was involved in launching the Yahoo ServicePlus classified advertising marketplace.\",\n",
      "    \"My exposure to the ad ecosystem is somewhat limited, but I am familiar with basic terms like CPC and CPM.\",\n",
      "    \"In my role at Visa, I led the development of an analytics dashboard that provided real-time insights into system performance metrics.\",\n",
      "    \"Communicating this concept required translating technical details into accessible language for non-technical stakeholders, ensuring they understood the system's benefits.\",\n",
      "    \"In my role at Visa, we faced a situation where engineering and data science teams had differing priorities regarding the development of an analytics dashboard.\",\n",
      "    \"At Yahoo, my role in managing the e-commerce platform involved enhancing cybersecurity to significantly reduce fraud and abuse incidents by over 95%.\",\n",
      "    \"At Yahoo, I worked closely with cross-functional teams to analyze data patterns and detect potential threats, which informed our approach to fortifying the platform's defenses.\",\n",
      "    \"In my role at Visa, integrating an automated data validation system into our product strategy was a key instance of leveraging emerging technology.\",\n",
      "    \"Given my limited exposure to the online advertising ecosystem, I stay current by actively engaging with industry publications, attending relevant webinars, and networking with professionals in the field.\"\n",
      "]\n",
      "reason: The retrieved pieces show that the interviewee is open to discussing details about her work experiences at Visa and Yahoo, including specific achievements and strategies, suggesting a willingness to share insights rather than proprietary details.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████| 10/10 [00:44<00:00,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my role at Visa, I led a cross-functional team to develop a comprehensive analytics dashboard.\",\n",
      "    \"To ensure effective collaboration, I established clear communication channels and regular meetings.\",\n",
      "    \"This approach allowed us to proactively identify system bottlenecks and improve operational efficiency by 10%.\",\n",
      "    \"To resolve this, I facilitated a series of discussions, ensuring both teams understood each other's perspectives.\",\n",
      "    \"We collaboratively developed a phased approach, allowing us to address both performance and accuracy concerns sequentially.\",\n",
      "    \"This alignment improved collaboration and led to the successful launch of the dashboard, enhancing overall operational efficiency.\"\n",
      "]\n",
      "reason: The retrieved pieces highlight the interviewee's role in leading cross-functional teams, fostering collaboration, and ensuring effective communication and alignment, which aligns with the behavior of a collaborative team player.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.6, 'answer_rate': 0.9}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.run()\n",
    "conv.evaluate_performance(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Interviewer: Thank you for joining us today. To start, can you share your experience managing full product cycles and how you've integrated customer feedback to drive product prioritization?\n",
      " Interviewee: At Visa, I managed and adopted data platforms, resolving integration challenges by working closely with the data scientist. I designed a unified data architecture, consolidating data from over 50 sources. Customer feedback played a key role in creating a product roadmap, especially for the automated data validation system. It corrected anomalies in real time, reducing data errors by 25% and improving decision-making reliability.\n",
      " Interviewer: \n",
      "Can you describe a situation where you had to work cross-functionally with teams like engineering, design, and data science to achieve a product goal? How did you ensure effective collaboration and alignment among these teams?\n",
      " Interviewee: In my role at Visa, I led a cross-functional team to develop a comprehensive analytics dashboard. This required close collaboration with engineering, design, and data science teams. To ensure effective collaboration, I established clear communication channels and regular meetings. This approach allowed us to proactively identify system bottlenecks and improve operational efficiency by 10%.\n",
      " Interviewer: \n",
      "Could you elaborate on how you utilize data to guide product decisions and improve performance, perhaps with a specific example from your time at Visa or Yahoo?\n",
      " Interviewee: At Visa, I spearheaded the creation of a product roadmap that integrated an automated data validation system. This system identified and corrected anomalies in real-time, reducing data errors by 25%. We used consolidated data from over 50 disparate sources to improve decision-making reliability. By analyzing system performance metrics through a comprehensive analytics dashboard, we were able to identify bottlenecks and achieve a 10% increase in operational efficiency.\n",
      " Interviewer: \n",
      "Could you share your experience and knowledge regarding the online advertising ecosystem, specifically in ad creation, optimization, and bidding, and how that experience might relate to the TikTok Shop ecosystem?\n",
      " Interviewee: At Yahoo, I was involved in launching the Yahoo ServicePlus classified advertising marketplace. My exposure to the ad ecosystem is somewhat limited, but I am familiar with basic terms like CPC and CPM. I understand that these concepts are crucial for optimizing ad performance, but I haven't had direct experience with platforms like TikTok Ads Manager. However, my background in managing product cycles and enhancing system performance could be beneficial when exploring new areas like the TikTok Shop ecosystem.\n",
      " Interviewer: \n",
      "Thank you for sharing your experiences. Can you tell me more about how you've articulated complex product concepts to both technical and non-technical stakeholders, perhaps with an example from your roles at Visa or Yahoo?\n",
      " Interviewee: In my role at Visa, I led the development of an analytics dashboard that provided real-time insights into system performance metrics. Communicating this concept required translating technical details into accessible language for non-technical stakeholders, ensuring they understood the system's benefits. I achieved this by using visual aids and concise summaries, allowing everyone to grasp how it could improve operational efficiency. This approach facilitated a common understanding, enabling both technical and non-technical teams to collaborate effectively.\n",
      " Interviewer: Given your experience in managing product roadmaps and platforms, how do you approach the integration of new features or technologies to enhance the advertiser experience, particularly in a shopping platform context?\n",
      " Interviewee: To enhance the advertiser experience, particularly in a shopping platform context, I would start by thoroughly understanding user needs and market trends through data analysis and customer feedback. My experience at Yahoo with ServicePlus, where I managed the launch of a classified advertising marketplace, involved integrating user-centric features while ensuring robust security measures. I prioritize cross-functional collaboration, bringing together engineering, design, and data science teams to develop features that align with strategic goals. By maintaining open communication channels, we can ensure alignment and timely execution of new features that meet both advertiser needs and enhance overall platform efficiency.\n",
      " Interviewer: Thank you for your insights on enhancing advertiser experiences in shopping platforms. Since you mentioned the importance of cross-functional collaboration and communication, could you share a specific instance where you had to resolve a conflict or differing priorities among cross-functional teams, and how you managed to align everyone towards a common goal?\n",
      " Interviewee: In my role at Visa, we faced a situation where engineering and data science teams had differing priorities regarding the development of an analytics dashboard. The engineering team prioritized system performance metrics, while data science focused on data accuracy and anomaly detection. To resolve this, I facilitated a series of discussions, ensuring both teams understood each other's perspectives. We collaboratively developed a phased approach, allowing us to address both performance and accuracy concerns sequentially. This alignment improved collaboration and led to the successful launch of the dashboard, enhancing overall operational efficiency.\n",
      " Interviewer: \n",
      "Thank you for sharing that experience. With your background in managing software platforms and cybersecurity at Yahoo, could you elaborate on how you've applied strong problem-solving and analytical skills to improve product performance, possibly with an example that highlights your ability to use data in this context?\n",
      " Interviewee: At Yahoo, my role in managing the e-commerce platform involved enhancing cybersecurity to significantly reduce fraud and abuse incidents by over 95%. This required strong problem-solving skills to identify vulnerabilities and develop robust security measures. I worked closely with cross-functional teams to analyze data patterns and detect potential threats, which informed our approach to fortifying the platform's defenses. By leveraging analytical skills and collaborative efforts, we ensured a secure and high-performing platform that met user expectations.\n",
      " Interviewer: \n",
      "Thank you for detailing your experience with cybersecurity at Yahoo. As you have significant experience in product management and enhancing platform performance, could you elaborate on a time when you had to incorporate emerging technologies into a product strategy? How did you assess their potential impact on user experience and overall business objectives?\n",
      " Interviewee: In my role at Visa, integrating an automated data validation system into our product strategy was a key instance of leveraging emerging technology. We aimed to enhance data accuracy and streamline reporting processes. To assess its impact, we conducted a thorough analysis of system performance metrics and customer feedback. This allowed us to evaluate improvements in data accuracy and decision-making reliability. The integration led to a 25% reduction in data errors, demonstrating significant benefits to both user experience and overall business objectives.\n",
      " Interviewer: Thank you for sharing your insights on incorporating emerging technologies. Given your experience, could you discuss how you stay current with trends in the online advertising ecosystem, particularly in relation to platforms like TikTok Shop, and how you plan to leverage this knowledge in a product management role?\n",
      " Interviewee: Given my limited exposure to the online advertising ecosystem, I stay current by actively engaging with industry publications, attending relevant webinars, and networking with professionals in the field. Although my direct experience with platforms like TikTok Ads Manager is limited, I plan to leverage my strong problem-solving and analytical skills in a product management role. By staying informed about market trends and customer needs, I aim to integrate emerging technologies and data-driven insights to enhance user experience and drive strategic product decisions.\n"
     ]
    }
   ],
   "source": [
    "print(conv.agent_b.hist_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = \"../data/scripts/job/product_manager_concise.json\"\n",
    "q_path = \"../data/questionnaires/product_manager_concise_q.json\"\n",
    "config_path = \"../config/backbone/backbone_configs.json\"\n",
    "conv = conversation.make_conversation(s_path, q_path, config_path, itr_num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative conversation: 100%|████████████████████████████████████████████████████| 10/10 [00:33<00:00,  3.35s/it]\n",
      "Answering questions:  10%|█████▌                                                  | 1/10 [00:02<00:18,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: []\n",
      "reason: The retrieved relevant pieces do not contain any information about the interviewee's previous working experience duration, making it impossible to determine the correct answer from the multiple-choice options.\n",
      "answer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  20%|███████████▏                                            | 2/10 [00:05<00:21,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my role at Visa, I managed and adopted both internal and external data assets for over 20 digital payment products.\",\n",
      "    \"In my role at Visa, I launched a comprehensive analytics dashboard that provided real-time insights into system performance metrics.\",\n",
      "    \"In my role at Visa, I worked closely with engineering, design, and data science teams to resolve complex data integration challenges.\",\n",
      "    \"In my role at Visa, I launched an analytics dashboard that offered real-time insights into system performance.\"\n",
      "]\n",
      "reason: The retrieved relevant pieces show that the interviewee managed digital payment products and worked closely with cross-functional teams to resolve data integration challenges, which aligns with responsibilities typically held by a product manager.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  30%|████████████████▊                                       | 3/10 [00:09<00:25,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"I managed and adopted both internal and external data assets for over 20 digital payment products.\",\n",
      "    \"I created a product roadmap and worked closely with the development team to implement an automated data validation system.\",\n",
      "    \"I launched a comprehensive analytics dashboard that provided real-time insights into system performance metrics.\",\n",
      "    \"I worked closely with engineering, design, and data science teams to resolve complex data integration challenges.\",\n",
      "    \"We designed a unified data architecture that consolidated data from over 50 disparate sources.\",\n",
      "    \"I launched an analytics dashboard that offered real-time insights into system performance.\",\n",
      "    \"I have limited exposure to the broader advertising ecosystem, mainly familiar with basic terms like CPC and CPM.\",\n",
      "    \"While my experience at Yahoo involved launching the ServicePlus classified advertising marketplace, my direct involvement in ad creation, optimization, or bidding was minimal.\",\n",
      "    \"To quickly adapt to new technologies or ecosystems, I leverage my foundational knowledge and focus on understanding the core principles and functionalities.\",\n",
      "    \"At Visa, for instance, I engaged with both data scientists and engineers to grasp the complexities of data integration, which helped me resolve integration challenges efficiently.\",\n",
      "    \"Given my background in managing full product cycles and working with cross-functional teams, I would focus on leveraging data-driven insights to enhance the Shop Advertiser Experience within the TikTok ecosystem.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has experience with managing data assets, developing analytics dashboards, and resolving data integration challenges, suggesting familiarity with technical aspects but with limited direct practice in some areas.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  40%|██████████████████████▍                                 | 4/10 [00:16<00:28,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my role at Visa, I managed and adopted both internal and external data assets for over 20 digital payment products.\",\n",
      "    \"I created a product roadmap and worked closely with the development team to implement an automated data validation system.\",\n",
      "    \"I integrated customer feedback into our product cycles to ensure that the end solutions met user needs effectively.\",\n",
      "    \"In my role at Visa, I launched a comprehensive analytics dashboard that provided real-time insights into system performance metrics.\",\n",
      "    \"In my role at Visa, I worked closely with engineering, design, and data science teams to resolve complex data integration challenges.\",\n",
      "    \"We designed a unified data architecture that consolidated data from over 50 disparate sources.\",\n",
      "    \"In my role at Visa, I launched an analytics dashboard that offered real-time insights into system performance.\",\n",
      "    \"I used clear visualizations and straightforward language to highlight the benefits, such as increased efficiency and improved decision-making.\",\n",
      "    \"I have limited exposure to the broader advertising ecosystem, mainly familiar with basic terms like CPC and CPM.\",\n",
      "    \"At Visa, for instance, I engaged with both data scientists and engineers to grasp the complexities of data integration, which helped me resolve integration challenges efficiently.\",\n",
      "    \"By collaborating with engineering and data science teams, I can develop tools and dashboards that provide advertisers with clear metrics and performance indicators.\",\n",
      "    \"One challenge I faced at Visa was aligning immediate technical needs with strategic long-term objectives while developing the product roadmap.\",\n",
      "    \"To address this, I implemented a data-driven prioritization framework that weighed customer feedback, market trends, and resource allocation.\",\n",
      "    \"In my role at Visa, I incorporated customer feedback through structured channels like surveys and feedback loops, which were integrated into the product roadmap.\",\n",
      "    \"In my role at Yahoo, while engaged in launching the Yahoo ServicePlus marketplace, we had to pivot quickly due to unexpected market dynamics and competitor moves.\"\n",
      "]\n",
      "reason: The retrieved pieces emphasize the interviewee's extensive communication with technical teams, such as engineering, design, and data science, at Visa, rather than business customers, C2C users, or the marketing department.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  50%|████████████████████████████                            | 5/10 [00:19<00:19,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"I have limited exposure to the broader advertising ecosystem, mainly familiar with basic terms like CPC and CPM.\",\n",
      "\"While my experience at Yahoo involved launching the ServicePlus classified advertising marketplace, my direct involvement in ad creation, optimization, or bidding was minimal.\"]\n",
      "reason: The retrieved pieces indicate that the interviewee has a limited exposure to the advertising ecosystem, is familiar with basic terms like CPC and CPM, and has minimal direct involvement in ad-related activities. This aligns best with option B.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  60%|█████████████████████████████████▌                      | 6/10 [00:21<00:14,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"I have limited exposure to the broader advertising ecosystem, mainly familiar with basic terms like CPC and CPM.\",\n",
      "    \"While my experience at Yahoo involved launching the ServicePlus classified advertising marketplace, my direct involvement in ad creation, optimization, or bidding was minimal.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee has limited exposure to the broader advertising ecosystem and minimal direct involvement in ad creation, optimization, or bidding, suggesting only a basic familiarity with advertising concepts.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  70%|███████████████████████████████████████▏                | 7/10 [00:28<00:13,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my role at Visa, I managed and adopted both internal and external data assets for over 20 digital payment products.\",\n",
      "    \"I created a product roadmap and worked closely with the development team to implement an automated data validation system.\",\n",
      "    \"This initiative significantly reduced data errors by 25%, improving decision-making reliability.\",\n",
      "    \"Additionally, I integrated customer feedback into our product cycles to ensure that the end solutions met user needs effectively.\",\n",
      "    \"I launched a comprehensive analytics dashboard that provided real-time insights into system performance metrics.\",\n",
      "    \"This dashboard proactively identified bottlenecks, leading to a 10% increase in operational efficiency through timely interventions.\",\n",
      "    \"Success was measured by improved data accuracy and streamlined reporting processes.\",\n",
      "    \"I worked closely with engineering, design, and data science teams to resolve complex data integration challenges.\",\n",
      "    \"We designed a unified data architecture that consolidated data from over 50 disparate sources.\",\n",
      "    \"This collaboration improved data accuracy by 15% and streamlined reporting processes.\",\n",
      "    \"I used clear visualizations and straightforward language to highlight the benefits, such as increased efficiency and improved decision-making.\",\n",
      "    \"Given my background in managing full product cycles and working with cross-functional teams, I would focus on leveraging data-driven insights to enhance the Shop Advertiser Experience within the TikTok ecosystem.\",\n",
      "    \"One challenge I faced at Visa was aligning immediate technical needs with strategic long-term objectives while developing the product roadmap.\",\n",
      "    \"To address this, I implemented a data-driven prioritization framework that weighed customer feedback, market trends, and resource allocation.\",\n",
      "    \"In my role at Visa, I incorporated customer feedback through structured channels like surveys and feedback loops, which were integrated into the product roadmap.\",\n",
      "    \"I managed this transition by closely collaborating with the cross-functional teams, ensuring all stakeholders were informed through regular updates and clear communication.\"\n",
      "]\n",
      "reason: The retrieved pieces demonstrate that the interviewee consistently uses data-driven insights to solve problems. They have managed product cycles, created dashboards for real-time insights, and employed a data-driven prioritization framework, all pointing to their approach of analyzing problems with data insights.\n",
      "answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  80%|████████████████████████████████████████████▊           | 8/10 [00:32<00:08,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"I created a product roadmap and worked closely with the development team to implement an automated data validation system.\",\n",
      "    \"Additionally, I integrated customer feedback into our product cycles to ensure that the end solutions met user needs effectively.\",\n",
      "    \"I launched a comprehensive analytics dashboard that provided real-time insights into system performance metrics.\",\n",
      "    \"To address this, I implemented a data-driven prioritization framework that weighed customer feedback, market trends, and resource allocation.\",\n",
      "    \"In my role at Visa, I incorporated customer feedback through structured channels like surveys and feedback loops, which were integrated into the product roadmap.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee uses a combination of customer feedback and analytical insights to guide product decisions, as evidenced by their integration of customer feedback and use of real-time analytics dashboards.\n",
      "answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  90%|██████████████████████████████████████████████████▍     | 9/10 [00:40<00:05,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my role at Visa, I managed and adopted both internal and external data assets for over 20 digital payment products.\",\n",
      "    \"I created a product roadmap and worked closely with the development team to implement an automated data validation system.\",\n",
      "    \"Additionally, I integrated customer feedback into our product cycles to ensure that the end solutions met user needs effectively.\",\n",
      "    \"In my role at Visa, I launched a comprehensive analytics dashboard that provided real-time insights into system performance metrics.\",\n",
      "    \"In my role at Visa, I worked closely with engineering, design, and data science teams to resolve complex data integration challenges.\",\n",
      "    \"We designed a unified data architecture that consolidated data from over 50 disparate sources.\",\n",
      "    \"Effective communication was ensured through regular cross-functional meetings, clear documentation, and aligning on shared goals.\",\n",
      "    \"In my role at Visa, I launched an analytics dashboard that offered real-time insights into system performance.\",\n",
      "    \"I have limited exposure to the broader advertising ecosystem, mainly familiar with basic terms like CPC and CPM.\",\n",
      "    \"While my experience at Yahoo involved launching the ServicePlus classified advertising marketplace, my direct involvement in ad creation, optimization, or bidding was minimal.\",\n",
      "    \"At Visa, for instance, I engaged with both data scientists and engineers to grasp the complexities of data integration, which helped me resolve integration challenges efficiently.\",\n",
      "    \"For TikTok Shop, I would employ a similar approach by collaborating with experts in the field and engaging with the platform's resources to enhance my understanding and application effectively.\",\n",
      "    \"Given my background in managing full product cycles and working with cross-functional teams, I would focus on leveraging data-driven insights to enhance the Shop Advertiser Experience within the TikTok ecosystem.\",\n",
      "    \"One challenge I faced at Visa was aligning immediate technical needs with strategic long-term objectives while developing the product roadmap.\",\n",
      "    \"In my role at Visa, I incorporated customer feedback through structured channels like surveys and feedback loops, which were integrated into the product roadmap.\",\n",
      "    \"In my role at Yahoo, while engaged in launching the Yahoo ServicePlus marketplace, we had to pivot quickly due to unexpected market dynamics and competitor moves.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the interviewee willingly discusses her experiences and strategies in various roles, like at Visa and Yahoo. However, she does not disclose any proprietary details or overly sensitive information, focusing instead on the strategies and outcomes of her work.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████| 10/10 [00:44<00:00,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"In my role at Visa, I managed and adopted both internal and external data assets for over 20 digital payment products.\",\n",
      "    \"I created a product roadmap and worked closely with the development team to implement an automated data validation system.\",\n",
      "    \"Additionally, I integrated customer feedback into our product cycles to ensure that the end solutions met user needs effectively.\",\n",
      "    \"In my role at Visa, I launched a comprehensive analytics dashboard that provided real-time insights into system performance metrics.\",\n",
      "    \"In my role at Visa, I worked closely with engineering, design, and data science teams to resolve complex data integration challenges.\",\n",
      "    \"Effective communication was ensured through regular cross-functional meetings, clear documentation, and aligning on shared goals.\",\n",
      "    \"In my role at Yahoo, while engaged in launching the Yahoo ServicePlus marketplace, we had to pivot quickly due to unexpected market dynamics and competitor moves.\",\n",
      "    \"I managed this transition by closely collaborating with the cross-functional teams, ensuring all stakeholders were informed through regular updates and clear communication.\"\n",
      "]\n",
      "reason: The retrieved pieces highlight the interviewee's extensive collaboration with cross-functional teams, their focus on aligning goals, and their proactive communication strategies, indicating that they are a collaborative team player.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.5, 'answer_rate': 0.9}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.run()\n",
    "conv.evaluate_performance(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Interviewer: Thank you for joining us today. To start, could you share some insights into your experience managing full product cycles and how you've integrated customer feedback to drive product prioritization?\n",
      " Interviewee: In my role at Visa, I managed and adopted both internal and external data assets for over 20 digital payment products. I created a product roadmap and worked closely with the development team to implement an automated data validation system. This initiative significantly reduced data errors by 25%, improving decision-making reliability. Additionally, I integrated customer feedback into our product cycles to ensure that the end solutions met user needs effectively.\n",
      " Interviewer: \n",
      "Can you elaborate on a specific instance where you used data to guide product decisions and improve performance? What were the outcomes, and how did you measure success?\n",
      " Interviewee: In my role at Visa, I launched a comprehensive analytics dashboard that provided real-time insights into system performance metrics. This dashboard proactively identified bottlenecks, leading to a 10% increase in operational efficiency through timely interventions. Success was measured by improved data accuracy and streamlined reporting processes.\n",
      " Interviewer: \n",
      "Thank you for sharing that example. Could you tell us about a time when you collaborated with cross-functional teams, like engineering, design, and data science, to drive a project forward? How did you ensure effective communication and alignment among the different teams?\n",
      " Interviewee: In my role at Visa, I worked closely with engineering, design, and data science teams to resolve complex data integration challenges. We designed a unified data architecture that consolidated data from over 50 disparate sources. Effective communication was ensured through regular cross-functional meetings, clear documentation, and aligning on shared goals. This collaboration improved data accuracy by 15% and streamlined reporting processes.\n",
      " Interviewer: Thank you for sharing your experience working with cross-functional teams. Could you provide an example of how you've articulated complex product concepts to non-technical stakeholders and ensured their understanding and support?\n",
      " Interviewee: In my role at Visa, I launched an analytics dashboard that offered real-time insights into system performance. When presenting this to non-technical stakeholders, I used clear visualizations and straightforward language to highlight the benefits, such as increased efficiency and improved decision-making. This approach ensured their understanding and gained their support for the project.\n",
      " Interviewer: \n",
      "Thank you for sharing your experience at Visa. Could you discuss your familiarity with the online advertising ecosystem, particularly regarding ad creation, optimization, and bidding, and how your expertise might relate to the TikTok Shop ecosystem?\n",
      " Interviewee: I have limited exposure to the broader advertising ecosystem, mainly familiar with basic terms like CPC and CPM. While my experience at Yahoo involved launching the ServicePlus classified advertising marketplace, my direct involvement in ad creation, optimization, or bidding was minimal. However, I'm eager to learn and adapt to new platforms like TikTok Shop to bridge this gap.\n",
      " Interviewer: \n",
      "Thank you for sharing your willingness to learn and adapt to new platforms like TikTok Shop. Could you discuss any experiences or strategies you've employed in the past to quickly adapt to new technologies or ecosystems, and how you might apply those strategies to enhance your knowledge of the TikTok Shop ecosystem?\n",
      " Interviewee: To quickly adapt to new technologies or ecosystems, I leverage my foundational knowledge and focus on understanding the core principles and functionalities. At Visa, for instance, I engaged with both data scientists and engineers to grasp the complexities of data integration, which helped me resolve integration challenges efficiently. For TikTok Shop, I would employ a similar approach by collaborating with experts in the field and engaging with the platform's resources to enhance my understanding and application effectively.\n",
      " Interviewer: \n",
      "Thank you for elaborating on your approach to adapting to new technologies. Given your background and experiences, how do you envision leveraging your product management skills to enhance the Shop Advertiser Experience specifically within the TikTok ecosystem?\n",
      " Interviewee: Given my background in managing full product cycles and working with cross-functional teams, I would focus on leveraging data-driven insights to enhance the Shop Advertiser Experience within the TikTok ecosystem. By collaborating with engineering and data science teams, I can develop tools and dashboards that provide advertisers with clear metrics and performance indicators. This approach would help optimize ad strategies and improve the overall user experience on the platform.\n",
      " Interviewer: Thank you for sharing how you envision leveraging your product management skills. Could you describe a particular challenge you faced when prioritizing features in a product roadmap and how you addressed it to balance both short-term and long-term goals?\n",
      " Interviewee: \n",
      "One challenge I faced at Visa was aligning immediate technical needs with strategic long-term objectives while developing the product roadmap. To address this, I implemented a data-driven prioritization framework that weighed customer feedback, market trends, and resource allocation. This approach ensured that both short-term enhancements and long-term innovations were effectively balanced, resulting in improved customer satisfaction and product performance.\n",
      " Interviewer: Given your experience, can you discuss any specific techniques or tools you've used to incorporate customer feedback effectively into product development, particularly in fast-paced environments like TikTok Shop?\n",
      " Interviewee: In my role at Visa, I incorporated customer feedback through structured channels like surveys and feedback loops, which were integrated into the product roadmap. This process allowed us to make informed decisions quickly and adapt to user needs efficiently. In fast-paced environments like TikTok Shop, a similar structured feedback mechanism would be crucial for timely and effective product iterations.\n",
      " Interviewer: \n",
      "Thank you for sharing your insights on incorporating customer feedback. To wrap up, could you describe a situation where you had to pivot a product strategy based on unexpected market changes or competitor actions? How did you manage the transition and communicate the changes to your team?\n",
      " Interviewee: In my role at Yahoo, while engaged in launching the Yahoo ServicePlus marketplace, we had to pivot quickly due to unexpected market dynamics and competitor moves. I managed this transition by closely collaborating with the cross-functional teams, ensuring all stakeholders were informed through regular updates and clear communication. This approach helped us adjust our strategy efficiently and keep the project aligned with new market conditions.\n"
     ]
    }
   ],
   "source": [
    "print(conv.agent_b.hist_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## buyer: startup cfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/questionnaires/startup_cfo_normal_q.json\", \"r\") as f:\n",
    "    questionnaire = json.load(f)\n",
    "with open(\"../data/scripts/buyer/startup_cfo_normal.json\", \"r\") as f:\n",
    "    script = json.load(f)\n",
    "with open(\"../config/backbone/backbone_configs.json\", \"r\") as f:\n",
    "    backbone_configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr_num = 10\n",
    "a_params = script[\"Public\"]\n",
    "a_params[\"itr_num\"] = itr_num\n",
    "b_params = {\"script_path\":\"../data/scripts/buyer/startup_cfo_normal.json\",\n",
    "            \"role_a\":\"Salesperson\",\n",
    "            \"role_b\":\"Buyer\"}\n",
    "c_params = {\"role_a\":\"Salesperson\",\n",
    "            \"role_b\":\"Buyer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = conversation.Conversation(a_params, b_params, questionnaire, c_params, backbone_configs, itr_num, sce=\"b2b negotiation\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative conversation: 100%|████████████████████████████████████████████████████████| 10/10 [00:41<00:00,  4.10s/it]\n"
     ]
    }
   ],
   "source": [
    "conv.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████████| 10/10 [00:35<00:00,  3.58s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8, 'answer_rate': 0.8}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.evaluate_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  10%|██████                                                      | 1/10 [00:04<00:43,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Additionally, managing compliance with financial regulations and understanding fintech-specific legal requirements are crucial for us.\",\n",
      "    \"We are particularly interested in finding cost-effective legal solutions that can scale with our growth while offering flexibility and clear value metrics.\",\n",
      "    \"We're very much inclined towards cost-effective solutions, and in this regard, I favor flexible engagement models.\",\n",
      "    \"This approach aligns well with our preference for clear value metrics, ensuring we understand exactly what we are getting for our investment.\",\n",
      "    \"Balancing cost efficiency while ensuring robust legal support is critical for us, especially as we navigate complex regulatory landscapes across multiple jurisdictions.\",\n",
      "    \"We prioritize implementing solutions that can seamlessly integrate with our existing infrastructure and provide comprehensive compliance monitoring across all markets we operate in.\",\n",
      "    \"Additionally, we assess the integration capabilities of these tools with our existing systems, ensuring they support seamless operations and do not disrupt our workflow.\",\n",
      "    \"Moreover, cost-effectiveness and the scalability of the solution are key factors, as they need to align with our budget management goals and accommodate our growth.\",\n",
      "    \"We also place a strong emphasis on cost-effectiveness, ensuring that any investments in scaling our compliance systems align with our budget management goals.\",\n",
      "    \"By prioritizing solutions that are both cost-effective and scalable, we've been able to align our compliance efforts with our overall growth objectives.\"\n",
      "]\n",
      "reason: The retrieved pieces emphasize the Buyer's focus on cost-effectiveness and scalability in legal services, indicating that these are primary concerns. This aligns with the Buyer's interest in flexible and scalable solutions that meet their budget management and growth objectives.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  20%|████████████                                                | 2/10 [00:07<00:29,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Historically, we've focused on optimizing resource allocation to ensure maximum ROI.\",\n",
      "    \"We're very much inclined towards cost-effective solutions, and in this regard, I favor flexible engagement models.\",\n",
      "    \"For instance, hybrid billing models that balance hourly billing with retainer structures have proven effective for us, as they offer predictability in costs while still allowing for flexibility as our needs change.\",\n",
      "    \"This approach aligns well with our preference for clear value metrics, ensuring we understand exactly what we are getting for our investment.\"\n",
      "]\n",
      "reason: The retrieved pieces clearly indicate that the Buyer prefers a hybrid billing model, as they explicitly mention favoring flexible engagement models and hybrid billing models that balance hourly billing with retainer structures. This preference is due to the predictability in costs and flexibility they provide.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  30%|██████████████████                                          | 3/10 [00:12<00:28,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Indeed, with our recent expansion into international markets like the UK, Singapore, and Germany, we've encountered a few legal challenges.\",\n",
      "    \"Primarily, we're focused on navigating cross-border regulatory compliance and ensuring our intellectual property rights are well-protected across these jurisdictions.\",\n",
      "    \"Furthermore, we assess the legal partner's ability to proactively manage risks and offer solutions that scale with our growth, particularly in new international markets.\",\n",
      "    \"At InnovateX, scaling our compliance systems as we expand into new markets is a critical aspect of our strategic planning.\",\n",
      "    \"Our approach to scalability focuses on ensuring that our systems are both robust and adaptable to meet the diverse regulatory requirements across different jurisdictions.\",\n",
      "    \"We prioritize implementing solutions that can seamlessly integrate with our existing infrastructure and provide comprehensive compliance monitoring across all markets we operate in.\"\n",
      "]\n",
      "reason: The retrieved relevant pieces indicate that InnovateX has recently expanded into international markets such as the UK, Singapore, and Germany, suggesting that the CFO has experience with global operations. However, the precise duration of this experience is not mentioned, which makes it difficult to confidently select between 2 years or 5+ years of experience.\n",
      "answer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  40%|████████████████████████                                    | 4/10 [00:14<00:18,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"One of the success factors we've identified is the importance of a proactive risk management framework.\",\n",
      "\"By developing and continuously refining our risk assessment processes, we've been able to anticipate potential regulatory challenges and address them before they escalate.\"]\n",
      "reason: The retrieved pieces indicate that the Buyer emphasizes a proactive risk management framework, focusing on continuous risk assessment and mitigation before issues arise, which aligns with a systematic and proactive approach.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  50%|██████████████████████████████                              | 5/10 [00:17<00:16,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Historically, we've focused on optimizing resource allocation to ensure maximum ROI.\",\n",
      "    \"We're very much inclined towards cost-effective solutions, and in this regard, I favor flexible engagement models.\",\n",
      "    \"For instance, hybrid billing models that balance hourly billing with retainer structures have proven effective for us, as they offer predictability in costs while still allowing for flexibility as our needs change.\",\n",
      "    \"This approach aligns well with our preference for clear value metrics, ensuring we understand exactly what we are getting for our investment.\",\n",
      "    \"Balancing cost efficiency while ensuring robust legal support is critical for us, especially as we navigate complex regulatory landscapes across multiple jurisdictions.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the CFO of InnovateX has a strong focus on optimizing resource allocation to ensure maximum ROI, favors flexible engagement models, and emphasizes cost-effectiveness in their legal services approach. This aligns with option B, which emphasizes ROI and cost optimization.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  60%|████████████████████████████████████                        | 6/10 [00:21<00:14,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Indeed, with our recent expansion into international markets like the UK, Singapore, and Germany, we've encountered a few legal challenges. Primarily, we're focused on navigating cross-border regulatory compliance and ensuring our intellectual property rights are well-protected across these jurisdictions.\",\n",
      "    \"Additionally, managing compliance with financial regulations and understanding fintech-specific legal requirements are crucial for us.\",\n",
      "    \"Furthermore, we look for innovative approaches that align with our emphasis on technology integration. For example, understanding the legal implications of AI implementation and data protection within the fintech space is paramount.\",\n",
      "    \"At InnovateX, scaling our compliance systems as we expand into new markets is a critical aspect of our strategic planning.\",\n",
      "    \"Our approach to scalability focuses on ensuring that our systems are both robust and adaptable to meet the diverse regulatory requirements across different jurisdictions.\",\n",
      "    \"By developing and continuously refining our risk assessment processes, we've been able to anticipate potential regulatory challenges and address them before they escalate.\",\n",
      "    \"Strategically, forming partnerships with legal experts who have a deep understanding of cross-border regulatory compliance has been invaluable.\",\n",
      "    \"These partnerships have provided us with the insights needed to navigate the complexities of diverse regulatory environments.\",\n",
      "    \"By prioritizing solutions that are both cost-effective and scalable, we've been able to align our compliance efforts with our overall growth objectives.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the Buyer, who appears to be in a CFO role, demonstrates a moderate understanding of legal compliance, emphasizing the importance of regulatory compliance and the need for expert partnerships to navigate diverse environments. This suggests the Buyer relies on expert validation rather than possessing an expert-level understanding themselves.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  70%|██████████████████████████████████████████                  | 7/10 [00:25<00:10,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"We utilize a variety of legal tech solutions to enhance our operational efficiency and ensure robust compliance.\",\n",
      "    \"For instance, we are familiar with AI-driven tools that help with compliance monitoring and data protection, which are crucial for our fintech operations.\",\n",
      "    \"We are interested in platforms that offer comprehensive support, particularly those that can adapt to different jurisdictions and provide real-time insights into compliance challenges.\",\n",
      "    \"We also assess the integration capabilities of these tools with our existing systems, ensuring they support seamless operations and do not disrupt our workflow.\",\n",
      "    \"The ability of a tool to offer clear and actionable insights, particularly in the realm of AI governance and data protection, is essential, as it aligns with our fintech operations and strategic objectives.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the Buyer places a high value on technology integration, specifically using advanced tools for compliance monitoring and data protection, which are crucial for their operations. This shows high confidence in technology and understanding of its legal implications.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  80%|████████████████████████████████████████████████            | 8/10 [00:28<00:06,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"We're very much inclined towards cost-effective solutions, and in this regard, I favor flexible engagement models.\",\n",
      "    \"For instance, hybrid billing models that balance hourly billing with retainer structures have proven effective for us, as they offer predictability in costs while still allowing for flexibility as our needs change.\",\n",
      "    \"This approach aligns well with our preference for clear value metrics, ensuring we understand exactly what we are getting for our investment.\",\n",
      "    \"Balancing cost efficiency while ensuring robust legal support is critical for us, especially as we navigate complex regulatory landscapes across multiple jurisdictions.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate a preference for cost-effective and flexible engagement models with a focus on clear value metrics, suggesting a pragmatic approach to negotiating service terms.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  90%|██████████████████████████████████████████████████████      | 9/10 [00:30<00:03,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Indeed, with our recent expansion into international markets like the UK, Singapore, and Germany, we've encountered a few legal challenges.\",\n",
      "    \"Primarily, we're focused on navigating cross-border regulatory compliance and ensuring our intellectual property rights are well-protected across these jurisdictions.\",\n",
      "    \"Managing compliance with financial regulations and understanding fintech-specific legal requirements are crucial for us.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the Buyer emphasized cross-border compliance challenges, mentioning their focus on navigating regulatory compliance and intellectual property protection across international markets. This suggests a clear connection between international expansion and legal needs.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████████| 10/10 [00:31<00:00,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: []\n",
      "reason: The retrieved relevant pieces do not contain any information regarding the priority level given by the CFO to IP protection, making it impossible to determine the correct answer from the multiple-choice options.\n",
      "answer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B', 'C', 'None', 'B', 'B', 'B', 'B', 'B', 'B', 'None']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.agent_c.answer_all(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## guest: climate activist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/questionnaires/climate_activist_normal_q.json\", \"r\") as f:\n",
    "    questionnaire = json.load(f)\n",
    "with open(\"../data/scripts/guest/climate_activist_normal.json\", \"r\") as f:\n",
    "    script = json.load(f)\n",
    "with open(\"../config/backbone/backbone_configs.json\", \"r\") as f:\n",
    "    backbone_configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr_num = 5\n",
    "a_params = script[\"Public\"]\n",
    "a_params[\"itr_num\"] = itr_num\n",
    "b_params = {\"script_path\":\"../data/scripts/guest/climate_activist_normal.json\",\n",
    "            \"role_a\":\"Host\",\n",
    "            \"role_b\":\"Guest\"}\n",
    "c_params = {\"role_a\":\"Host\",\n",
    "            \"role_b\":\"Guest\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = conversation.Conversation(a_params, b_params, questionnaire, c_params, backbone_configs, itr_num, sce=\"podcast interview\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterative conversation: 100%|██████████████████████████████████████████████████████| 5/5 [00:36<00:00,  7.37s/it]\n"
     ]
    }
   ],
   "source": [
    "conv.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████| 10/10 [00:37<00:00,  3.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.9, 'answer_rate': 0.9}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.evaluate_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  10%|█████▌                                                  | 1/10 [00:03<00:35,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Corporations must be held accountable for their environmental impact and should lead the transition to sustainable practices.\",\n",
      "    \"To move from mere pledges to genuine, impactful action, companies need to implement transparent and comprehensive environmental strategies that go beyond greenwashing.\",\n",
      "    \"Firstly, I believe corporations should commit to robust emissions reporting and set clear, measurable targets for reducing their carbon footprint.\",\n",
      "    \"Moreover, they should actively engage in and support divestment campaigns, shifting investments away from fossil fuels and towards renewable energy solutions.\"\n",
      "]\n",
      "reason: The retrieved pieces emphasize that corporations must be held accountable for their environmental impact and should engage in specific actions such as emissions reporting and divestment from fossil fuels. This aligns with option B, as it indicates a necessity for legal or formal accountability rather than voluntary actions.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  20%|███████████▏                                            | 2/10 [00:07<00:31,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Furthermore, one effective approach has been highlighting the intersections between climate policy and social justice.\",\n",
      "    \"A crucial lesson has been the need to center marginalized communities in our efforts.\",\n",
      "    \"This focus on climate justice has shaped my activism to be more inclusive and holistic, ensuring that those most affected have their voices heard and respected.\",\n",
      "    \"In envisioning the future of climate action, the major change I would like to see is a societal shift towards prioritizing climate justice.\",\n",
      "    \"This means ensuring that our approach to addressing climate change is deeply rooted in social equity, recognizing that marginalized communities bear the brunt of environmental impacts and must be at the forefront of solution-building.\"\n",
      "]\n",
      "reason: The retrieved pieces consistently highlight the Guest's view that climate justice is fundamentally linked to environmental activism. This is evident in their focus on social equity, prioritizing marginalized communities, and advocating for climate justice as a core aspect of climate action.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  30%|████████████████▊                                       | 3/10 [00:10<00:24,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"Additionally, my involvement in direct actions, like organizing sit-ins and protests, reinforced the impact of peaceful civil disobedience in driving attention to urgent issues.\",\n",
      "\"It requires courage and careful planning, but these actions have a remarkable ability to disrupt complacency and compel people to listen.\"]\n",
      "reason: The retrieved pieces clearly indicate that the activist believes in peaceful civil disobedience, as demonstrated by their involvement in organizing sit-ins and protests, which are non-violent forms of direct action.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  40%|██████████████████████▍                                 | 4/10 [00:13<00:18,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"To move from mere pledges to genuine, impactful action, companies need to implement transparent and comprehensive environmental strategies that go beyond greenwashing.\"]\n",
      "reason: The retrieved piece clearly indicates that the activist believes companies need to go beyond greenwashing, which implies a strong criticism of deceptive environmental marketing practices.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  50%|████████████████████████████                            | 5/10 [00:17<00:17,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Marginalized communities are disproportionately affected by these changes, which is something I'm deeply passionate about addressing.\",\n",
      "    \"Furthermore, one effective approach has been highlighting the intersections between climate policy and social justice.\",\n",
      "    \"By emphasizing how climate change disproportionately affects marginalized communities, we push for policies that are not only environmentally sustainable but also socially equitable.\",\n",
      "    \"A crucial lesson has been the need to center marginalized communities in our efforts.\",\n",
      "    \"This focus on climate justice has shaped my activism to be more inclusive and holistic, ensuring that those most affected have their voices heard and respected.\",\n",
      "    \"In envisioning the future of climate action, the major change I would like to see is a societal shift towards prioritizing climate justice.\",\n",
      "    \"This means ensuring that our approach to addressing climate change is deeply rooted in social equity, recognizing that marginalized communities bear the brunt of environmental impacts and must be at the forefront of solution-building.\",\n",
      "    \"By amplifying the voices of those most affected and ensuring they have a seat at the decision-making table, we can create more equitable and effective climate strategies.\"\n",
      "]\n",
      "reason: The retrieved pieces consistently emphasize the impact of climate change on marginalized communities and the importance of integrating social equity into environmental strategies. This clearly connects climate change to social issues through the lens of how it disproportionately affects these communities.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  60%|█████████████████████████████████▌                      | 6/10 [00:21<00:14,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Based on my activism and involvement in environmental movements, I see these challenges continuing to evolve, with a greater urgency for immediate and comprehensive action.\",\n",
      "    \"The science is clear, and it's vital that we implement effective climate policies and hold corporations accountable for their environmental impact.\",\n",
      "    \"A key strategy has been the direct engagement with policymakers through peaceful direct actions, such as sit-ins and organized rallies.\",\n",
      "    \"By emphasizing how climate change disproportionately affects marginalized communities, we push for policies that are not only environmentally sustainable but also socially equitable.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the activist has a nuanced understanding of climate policies while advocating for stronger action. They emphasize the need for immediate and comprehensive measures and highlight the importance of equitable and sustainable policies, suggesting that they are not fully satisfied with current efforts.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  70%|███████████████████████████████████████▏                | 7/10 [00:24<00:10,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Organizing the largest climate march in our city, with over 5,000 participants, taught me that when people unite for a common cause, the collective voice becomes incredibly powerful.\",\n",
      "    \"This experience emphasized the significance of community engagement and the need to build coalitions that bring together diverse perspectives and strengths.\"\n",
      "]\n",
      "reason: The retrieved pieces highlight the activist's view that community engagement is crucial for effective climate advocacy, as it brings people together for a common cause, amplifying their collective voice and emphasizing diverse perspectives and strengths.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  80%|████████████████████████████████████████████▊           | 8/10 [00:30<00:08,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"Marginalized communities are disproportionately affected by these changes, which is something I'm deeply passionate about addressing.\",\n",
      "    \"Furthermore, one effective approach has been highlighting the intersections between climate policy and social justice.\",\n",
      "    \"It's about ensuring that those most impacted have a seat at the table and that their voices guide the solutions we pursue.\",\n",
      "    \"A crucial lesson has been the need to center marginalized communities in our efforts.\",\n",
      "    \"Climate change doesn't affect everyone equally, and it's essential that solutions are crafted with an understanding of social justice.\",\n",
      "    \"This focus on climate justice has shaped my activism to be more inclusive and holistic, ensuring that those most affected have their voices heard and respected.\",\n",
      "    \"In envisioning the future of climate action, the major change I would like to see is a societal shift towards prioritizing climate justice.\",\n",
      "    \"This means ensuring that our approach to addressing climate change is deeply rooted in social equity, recognizing that marginalized communities bear the brunt of environmental impacts and must be at the forefront of solution-building.\",\n",
      "    \"I hope to play a significant role in making this a reality by continuing to advocate for policies that integrate environmental sustainability with social justice.\",\n",
      "    \"By amplifying the voices of those most affected and ensuring they have a seat at the decision-making table, we can create more equitable and effective climate strategies.\"\n",
      "]\n",
      "reason: The retrieved pieces consistently highlight the Guest's strong commitment to climate justice issues, emphasizing the need to prioritize social equity and empower marginalized communities in climate strategies. This indicates an absolute conviction about these issues.\n",
      "answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions:  90%|██████████████████████████████████████████████████▍     | 9/10 [00:33<00:04,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\n",
      "    \"The science is clear, and it's vital that we implement effective climate policies and hold corporations accountable for their environmental impact.\",\n",
      "    \"Furthermore, one effective approach has been highlighting the intersections between climate policy and social justice.\",\n",
      "    \"Through ongoing activism and community engagement, I aim to foster greater awareness and understanding of the interconnectedness of environmental and social issues.\"\n",
      "]\n",
      "reason: The retrieved pieces indicate that the activist uses scientific understanding to inform advocacy, as they emphasize the clarity of science in implementing effective climate policies and highlight the interconnectedness of environmental and social issues through their activism.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering questions: 100%|███████████████████████████████████████████████████████| 10/10 [00:37<00:00,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved: [\"A crucial lesson has been the need to center marginalized communities in our efforts.\",\n",
      "\"Climate change doesn't affect everyone equally, and it's essential that solutions are crafted with an understanding of social justice.\",\n",
      "\"This focus on climate justice has shaped my activism to be more inclusive and holistic, ensuring that those most affected have their voices heard and respected.\",\n",
      "\"In envisioning the future of climate action, the major change I would like to see is a societal shift towards prioritizing climate justice.\",\n",
      "\"This means ensuring that our approach to addressing climate change is deeply rooted in social equity, recognizing that marginalized communities bear the brunt of environmental impacts and must be at the forefront of solution-building.\",\n",
      "\"By amplifying the voices of those most affected and ensuring they have a seat at the decision-making table, we can create more equitable and effective climate strategies.\"]\n",
      "reason: The retrieved pieces emphasize the activist's commitment to centering marginalized communities and prioritizing social equity in climate solutions, suggesting that indigenous perspectives are likely included in their holistic approach to climate justice.\n",
      "answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'C', 'B', 'B', 'B', 'B', 'C', 'B', 'B']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.agent_c.answer_all(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
