{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3429d21-ea7c-4b93-ab62-c1b8844582c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Clarice Wang\n",
      "650-250-3130 | clarice7@seas.upenn.edu | linkedin.com/in/claricewang\n",
      "Education\n",
      "University of Pennsylvania Philadelphia, PA\n",
      "BSE Computer Science | Minors: Math, Economics Aug. 2022 – May 2026\n",
      "• Fall 2024: CIS 7000 Large Language Models, CIS 5500 Databases, CIS 5210 Artificial Intelligence\n",
      "Experience\n",
      "Data Science Intern October 2024 – Present\n",
      "Shelflife Philadelphia, PA\n",
      "• Building a markdowns optimizer with LLMs and causal inference techniques.\n",
      "Head Teaching Assistant August 2024 – Present\n",
      "University of Pennsylvania, CIS 7000 Conversations and Conversational Bots Philadelphia, PA\n",
      "• Developing and teaching material on building and testing LLM-based chatbots.\n",
      "Machine Learning Engineer July 2024 – Present\n",
      "Avary Remote\n",
      "• Researching and evaluating LLM multi-turn conversations for a 3-agent conversation management pipeline.\n",
      "Value Engineering Intern June 2024 – Aug 2024\n",
      "Celonis New York, NY\n",
      "• Used LLMs for the semantic understanding of decision trees for Celonis Action Flows with DSPy and TextGrad.\n",
      "• Framed value for five Life Sciences clients in determining AP/AR and order/inventory management insights.\n",
      "• Discovered and created GTM content for value engineers and account executives in the Life Sciences vertical.\n",
      "• Developed a product feedback loop for tracking sustainability metrics and integrating data across Salesforce.\n",
      "Investment Associate May 2024 – Sep 2024\n",
      "Fellows Fund San Jose, CA\n",
      "• Conducted thorough due diligence on prospective AI startup investments.\n",
      "• Analyzed enterprise market segments to identify potential investment opportunities and market gaps.\n",
      "• Screened Y Combinator batches for sourcing founder conversations.\n",
      "Projects\n",
      "Petco Creative| Python, OpenAI, HuggingFace, Github Feb. 2024 – May 2024\n",
      "• Determined the “best” creative content for email advertising by building a RAG model for email text content and\n",
      "simulating customers’ response to images using LLM user agents as opposed to A/B testing.\n",
      "Penn Kudos| React, Sentiment Analysis, Javascript, Figma, Agile Jan. 2024 – May 2024\n",
      "• Full-stack web app for the Penn community to submit anonymous or named compliments about each other.\n",
      "Business Trend Prediction Model| Python, BERTopic, Webscraping, Data Analysis Sep. 2023 – Dec. 2023\n",
      "• Penn Data Science Group project for a Wharton subsidiary client.\n",
      "Pricing and Supply Optimization| Python, Jupyter Notebook, Data Analysis Feb. 2023 – May 2023\n",
      "• Engineering Consultants at Penn project for a phygital startup client.\n",
      "Publications\n",
      "When Biased Humans Meet Debiased AI: A Case Study in College Major Recommendation, in ACM\n",
      "Transactions on Interactive Intelligent Systems (TiiS):1–28, September 2023.\n",
      "User Acceptance of Gender Stereotypes in Automated Career Recommendations, in ACM Intelligent User\n",
      "Interfaces (IUI):134-147, March 2022.\n",
      "Understanding the EM algorithm (with code and visualizations), in Medium, 2022.\n",
      "AI for Healthcare: The Promise and Challenges, in Medium, 2021.\n",
      "Technical Skills\n",
      "Languages: Python, Java, OCaml, R, SQL, C, HTML/CSS, JavaScript, TypeScript\n",
      "Frameworks: PyTorch, React, Node.js, JUnit, Vue.js, LangChain, Gradio, Streamlit, Cypress\n",
      "Developer Tools: Jupyter Notebook, VS Code, Git, Bash, LaTeX, PyCharm, IntelliJ, Word, Excel, PowerPoint, Figma\n",
      "Libraries: Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, BeautifulSoup, Requests, Plotly, NLTK\n"
     ]
    }
   ],
   "source": [
    "# importing required modules\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# creating a pdf reader object\n",
    "reader = PdfReader('./2026_CIS_ClariceWang.pdf')\n",
    "\n",
    "# printing number of pages in pdf file\n",
    "print(len(reader.pages))\n",
    "\n",
    "# getting a specific page from the pdf file\n",
    "page = reader.pages[0]\n",
    "\n",
    "# extracting text from page\n",
    "text = page.extract_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f69708a-04d9-412b-8bd8-e55c5efb1a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://jobs.apple.com/en-us/details/200546866/software-engineer\n",
    "role = \"\"\"\n",
    "{\n",
    "  \"Title\": \"Software Engineer\",\n",
    "  \"Location\": \"Sunnyvale, California, United States\",\n",
    "  \"Department\": \"Software and Services\",\n",
    "  \"Summary\": \"Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish.\n",
    "  \\nThe people here at Apple don’t just create products — they create the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. \n",
    "  \\nApple's Manufacturing Systems & Infrastructure (MSI) team is responsible for gathering, consolidating and tracking all manufacturing data for Apple’s products and modules worldwide. This data is used throughout the company and the product's lifecycle, from the very beginning, to validate that units being built are fully tested and of high quality before leaving the factory, all of the way through to warranty support for customers. Apple's MSI team is seeking a Software Engineer who possesses a real passion for developing extraordinary products with a deep appreciation for user experience. We are looking for a passionate and results-oriented Software Engineer to join our team and work on some of the highly visible data projects in Operations organization!\",\n",
    "  \"Description\": \"In this role you will be responsible for defining and developing ML Platform and frameworks for generative AI powered applications at Apple Product Operations\n",
    "  \\nYou will be responsible in crafting, developing and maintaining our large-scale systems, storage, and integration services\n",
    "  \\nYou will collaborate with diverse cross-functional partners, including model developers, machine learning systems engineers, data scientists, application developers and product managers\n",
    "  \\nYou will work closely with the SRE team and develop monitoring and alerting on various applications and systems integrations.\n",
    "  \\nYou will have the opportunity to learn and work on the latest technologies, lead POCs to demonstrate new ideas and influence the future direction of our technology stack\",\n",
    "  \"Minimum Qualifications\": \"3+ years of hands on micro services development experience using industry standard frameworks.\n",
    "  \\nBachelor’s degree or in Computer Science, Engineering or equivalent experience\",\n",
    "  \"Preferred Qualifications\": \"Strong software development, problem-solving and debugging skills with experience in one or more of the following languages: Python, Java, Go\n",
    "  \\nExperience building a RESTful API with at least one backend language such as Python, Java, Go\n",
    "  \\nExperience in writing and tuning SQL queries and using data stores like Relational, NoSQL and Object Stores\n",
    "  \\nExperience building cloud native platforms using containerization technologies like Kubernetes, docker, helm and well versed in AWS/GCP or Azure\n",
    "  \\nExperience with big data processing and message queue platforms like Kafka, Spark, Iceberg and Trino.\n",
    "  \\nAdept at quickly grasping and distilling highly complex matters into clean, understandable solutions\n",
    "  \\nSelf directed, self motivated and detail oriented with ability to come up with good design proposals and thorough analysis of production issues\n",
    "  \\nCandidate should be able to initiate and explore alternate technology and approaches to solving problems.\n",
    "  \\nStrong communication and Collaboration skills.\",\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5877da9d-3dff-4389-bc14-73209a0e8d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter OpenAI API key:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "import openai\n",
    "import os\n",
    "\n",
    "print('Enter OpenAI API key:')\n",
    "openai.api_key = getpass()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae6844d8-ab24-41ab-88e4-664a29645a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import time\n",
    "\n",
    "def generate_candidate_attributes(resume):\n",
    "  system_prompt = f\"\"\"\n",
    "  Given a candidate's resume, you create a JSON file of the candidate's attributes.\n",
    "  Do NOT generate or infer any information about the candidate that is not on their resume. If any information is missing, leave the column null.\n",
    "  The JSON file should include the following columns:\n",
    "  \\n\\n\n",
    "  Name\n",
    "  Email\n",
    "  Phone Number\n",
    "  LinkedIn\n",
    "  Address\n",
    "  Institution\n",
    "  Degree (Bachelor/Master/PhD)\n",
    "  Majors\n",
    "  Minors\n",
    "  Graduation Date\n",
    "  Experience\n",
    "  Projects\n",
    "  Publications\n",
    "  Technical Skills\n",
    "  Non-Technical Skills\n",
    "  \"\"\"\n",
    "\n",
    "  client = openai.OpenAI()\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages= [\n",
    "          {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "          {\"role\" : \"user\", \"content\" : resume}\n",
    "      ],\n",
    "      temperature=0.7,\n",
    "      max_tokens=2048,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "  )\n",
    "  time.sleep(1)\n",
    "\n",
    "  return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "580aad70-fb87-4468-98d0-4022d345d257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Name\": \"Clarice Wang\",\n",
      "  \"Email\": \"clarice7@seas.upenn.edu\",\n",
      "  \"Phone Number\": \"650-250-3130\",\n",
      "  \"LinkedIn\": \"linkedin.com/in/claricewang\",\n",
      "  \"Address\": null,\n",
      "  \"Institution\": \"University of Pennsylvania\",\n",
      "  \"Degree\": \"Bachelor\",\n",
      "  \"Majors\": \"Computer Science\",\n",
      "  \"Minors\": \"Math, Economics\",\n",
      "  \"Graduation Date\": \"May 2026\",\n",
      "  \"Experience\": [\n",
      "    {\n",
      "      \"Position\": \"Data Science Intern\",\n",
      "      \"Company\": \"Shelflife\",\n",
      "      \"Location\": \"Philadelphia, PA\",\n",
      "      \"Start Date\": \"October 2024\",\n",
      "      \"End Date\": \"Present\",\n",
      "      \"Description\": \"Building a markdowns optimizer with LLMs and causal inference techniques.\"\n",
      "    },\n",
      "    {\n",
      "      \"Position\": \"Head Teaching Assistant\",\n",
      "      \"Company\": \"University of Pennsylvania\",\n",
      "      \"Location\": \"Philadelphia, PA\",\n",
      "      \"Start Date\": \"August 2024\",\n",
      "      \"End Date\": \"Present\",\n",
      "      \"Description\": \"Developing and teaching material on building and testing LLM-based chatbots.\"\n",
      "    },\n",
      "    {\n",
      "      \"Position\": \"Machine Learning Engineer\",\n",
      "      \"Company\": \"Avary\",\n",
      "      \"Location\": \"Remote\",\n",
      "      \"Start Date\": \"July 2024\",\n",
      "      \"End Date\": \"Present\",\n",
      "      \"Description\": \"Researching and evaluating LLM multi-turn conversations for a 3-agent conversation management pipeline.\"\n",
      "    },\n",
      "    {\n",
      "      \"Position\": \"Value Engineering Intern\",\n",
      "      \"Company\": \"Celonis\",\n",
      "      \"Location\": \"New York, NY\",\n",
      "      \"Start Date\": \"June 2024\",\n",
      "      \"End Date\": \"August 2024\",\n",
      "      \"Description\": \"Used LLMs for the semantic understanding of decision trees for Celonis Action Flows with DSPy and TextGrad. Framed value for five Life Sciences clients in determining AP/AR and order/inventory management insights. Discovered and created GTM content for value engineers and account executives in the Life Sciences vertical. Developed a product feedback loop for tracking sustainability metrics and integrating data across Salesforce.\"\n",
      "    },\n",
      "    {\n",
      "      \"Position\": \"Investment Associate\",\n",
      "      \"Company\": \"Fellows Fund\",\n",
      "      \"Location\": \"San Jose, CA\",\n",
      "      \"Start Date\": \"May 2024\",\n",
      "      \"End Date\": \"Sep 2024\",\n",
      "      \"Description\": \"Conducted thorough due diligence on prospective AI startup investments. Analyzed enterprise market segments to identify potential investment opportunities and market gaps. Screened Y Combinator batches for sourcing founder conversations.\"\n",
      "    }\n",
      "  ],\n",
      "  \"Projects\": [\n",
      "    {\n",
      "      \"Project\": \"Petco Creative\",\n",
      "      \"Technologies\": \"Python, OpenAI, HuggingFace, Github\",\n",
      "      \"Date\": \"Feb. 2024 – May 2024\",\n",
      "      \"Description\": \"Determined the “best” creative content for email advertising by building a RAG model for email text content and simulating customers’ response to images using LLM user agents as opposed to A/B testing.\"\n",
      "    },\n",
      "    {\n",
      "      \"Project\": \"Penn Kudos\",\n",
      "      \"Technologies\": \"React, Sentiment Analysis, Javascript, Figma, Agile\",\n",
      "      \"Date\": \"Jan. 2024 – May 2024\",\n",
      "      \"Description\": \"Full-stack web app for the Penn community to submit anonymous or named compliments about each other.\"\n",
      "    },\n",
      "    {\n",
      "      \"Project\": \"Business Trend Prediction Model\",\n",
      "      \"Technologies\": \"Python, BERTopic, Webscraping, Data Analysis\",\n",
      "      \"Date\": \"Sep. 2023 – Dec. 2023\",\n",
      "      \"Description\": \"Penn Data Science Group project for a Wharton subsidiary client.\"\n",
      "    },\n",
      "    {\n",
      "      \"Project\": \"Pricing and Supply Optimization\",\n",
      "      \"Technologies\": \"Python, Jupyter Notebook, Data Analysis\",\n",
      "      \"Date\": \"Feb. 2023 – May 2023\",\n",
      "      \"Description\": \"Engineering Consultants at Penn project for a phygital startup client.\"\n",
      "    }\n",
      "  ],\n",
      "  \"Publications\": [\n",
      "    {\n",
      "      \"Title\": \"When Biased Humans Meet Debiased AI: A Case Study in College Major Recommendation\",\n",
      "      \"Journal\": \"ACM Transactions on Interactive Intelligent Systems (TiiS)\",\n",
      "      \"Date\": \"September 2023\"\n",
      "    },\n",
      "    {\n",
      "      \"Title\": \"User Acceptance of Gender Stereotypes in Automated Career Recommendations\",\n",
      "      \"Journal\": \"ACM Intelligent User Interfaces (IUI)\",\n",
      "      \"Date\": \"March 2022\"\n",
      "    },\n",
      "    {\n",
      "      \"Title\": \"Understanding the EM algorithm (with code and visualizations)\",\n",
      "      \"Journal\": \"Medium\",\n",
      "      \"Date\": \"2022\"\n",
      "    },\n",
      "    {\n",
      "      \"Title\": \"AI for Healthcare: The Promise and Challenges\",\n",
      "      \"Journal\": \"Medium\",\n",
      "      \"Date\": \"2021\"\n",
      "    }\n",
      "  ],\n",
      "  \"Technical Skills\": {\n",
      "    \"Languages\": [\n",
      "      \"Python\",\n",
      "      \"Java\",\n",
      "      \"OCaml\",\n",
      "      \"R\",\n",
      "      \"SQL\",\n",
      "      \"C\",\n",
      "      \"HTML/CSS\",\n",
      "      \"JavaScript\",\n",
      "      \"TypeScript\"\n",
      "    ],\n",
      "    \"Frameworks\": [\n",
      "      \"PyTorch\",\n",
      "      \"React\",\n",
      "      \"Node.js\",\n",
      "      \"JUnit\",\n",
      "      \"Vue.js\",\n",
      "      \"LangChain\",\n",
      "      \"Gradio\",\n",
      "      \"Streamlit\",\n",
      "      \"Cypress\"\n",
      "    ],\n",
      "    \"Developer Tools\": [\n",
      "      \"Jupyter Notebook\",\n",
      "      \"VS Code\",\n",
      "      \"Git\",\n",
      "      \"Bash\",\n",
      "      \"LaTeX\",\n",
      "      \"PyCharm\",\n",
      "      \"IntelliJ\",\n",
      "      \"Word\",\n",
      "      \"Excel\",\n",
      "      \"PowerPoint\",\n",
      "      \"Figma\"\n",
      "    ],\n",
      "    \"Libraries\": [\n",
      "      \"Pandas\",\n",
      "      \"NumPy\",\n",
      "      \"Matplotlib\",\n",
      "      \"Seaborn\",\n",
      "      \"Scikit-learn\",\n",
      "      \"BeautifulSoup\",\n",
      "      \"Requests\",\n",
      "      \"Plotly\",\n",
      "      \"NLTK\"\n",
      "    ]\n",
      "  },\n",
      "  \"Non-Technical Skills\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "attributes_raw = generate_candidate_attributes(text)\n",
    "print(attributes_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7720e037-eff7-4262-a12a-fb5dd7371615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_missing_information(attributes, role):\n",
    "  system_prompt = f\"\"\"\n",
    "  You are a hiring manager for the following role:\\n\\n{role}.\n",
    "  \\n\\nGiven a candidate's resume (JSON format), determine what information is missing about the candidate that you want to know about them.\n",
    "  \"\"\"\n",
    "\n",
    "  client = openai.OpenAI()\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages= [\n",
    "          {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "          {\"role\" : \"user\", \"content\" : attributes}\n",
    "      ],\n",
    "      temperature=0.7,\n",
    "      max_tokens=2048,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "  )\n",
    "  time.sleep(1)\n",
    "\n",
    "  return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c2bc260-0343-4e4e-8fbf-aadbfa4f4ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on Clarice Wang's resume, here are some missing pieces of information that would be valuable to know for the Software Engineer position at Apple:\n",
      "\n",
      "1. **Address**: It would be helpful to know Clarice's current location or at least a general idea of where she is based.\n",
      "\n",
      "2. **Non-Technical Skills**: Understanding Clarice's non-technical skills such as communication, teamwork, leadership, problem-solving, and others would provide a more holistic view of her capabilities.\n",
      "\n",
      "3. **Certifications**: Any relevant certifications in software engineering, machine learning, or related fields would be beneficial to assess her qualifications.\n",
      "\n",
      "4. **Specific Experience with ML Platforms**: While Clarice has experience with ML technologies, understanding if she has specific experience with ML platforms like the ones mentioned in the job description (generative AI powered applications, big data processing, message queue platforms) would be important.\n",
      "\n",
      "5. **Cloud Platform Experience**: Clarice mentions technologies like Kubernetes, Docker, and AWS/GCP/Azure, but specific experience working with these cloud platforms in a professional setting would be useful to gauge her expertise.\n",
      "\n",
      "6. **Experience with Monitoring and Alerting Systems**: Given the role's requirement to work closely with the SRE team on monitoring and alerting systems, it would be beneficial to know if Clarice has worked on similar systems in the past.\n",
      "\n",
      "7. **Leadership and Project Management Skills**: Understanding if Clarice has led projects, managed teams, or demonstrated strong project management skills would be important for a role that involves collaboration with cross-functional partners.\n",
      "\n",
      "8. **Industry Experience**: While Clarice has diverse internship experiences, knowing if she has any prior experience in the manufacturing or tech industry, particularly related to operations or software development, would be relevant.\n",
      "\n",
      "9. **Professional Development Initiatives**: Any initiatives taken by Clarice to further her professional development, such as attending workshops, courses, or conferences related to software engineering, would showcase her commitment to growth in the field.\n",
      "\n",
      "By gathering this additional information, we can more accurately assess Clarice's fit for the Software Engineer position at Apple within the Manufacturing Systems & Infrastructure team.\n"
     ]
    }
   ],
   "source": [
    "missing_info = generate_missing_information(attributes_raw, role)\n",
    "print(missing_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "40629384-3eae-43df-a7d6-3c717435e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(attributes, role, missing_info):\n",
    "  system_prompt = f\"\"\"\n",
    "  You are a hiring manager for the following role:\\n\\n{role}.\n",
    "  \\n\\nYou are missing the following information from the candidate:\\n\\n{missing_info}\n",
    "  \\n\\nGiven the candidate's resume (JSON format), come up with the following questions so that you can figure out whether they are right for the role:\n",
    "  \\n\\n5 behavioral questions with the goal of having the candidate expand upon their experiences, labeled B1-B5\n",
    "  \\n5 technical questions with the goal of having the candidate demonstrate their skills, labeled T1-T5\n",
    "  \\n\\n Format the output in a python dictionary \"B1\":\"question\",...,\"B5\":\"question\", \"T1\":\"question\",...,\"T5\":\"question\"\\}.\n",
    "  \"\"\"\n",
    "\n",
    "  client = openai.OpenAI()\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages= [\n",
    "          {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "          {\"role\" : \"user\", \"content\" : attributes}\n",
    "      ],\n",
    "      temperature=0.7,\n",
    "      max_tokens=2048,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "  )\n",
    "  time.sleep(1)\n",
    "\n",
    "  return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "047b633a-6df1-487c-830c-0d730a7e20a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"B1\": \"Can you describe a challenging project you worked on as a Machine Learning Engineer at Avary and how you approached solving it?\",\n",
      "    \"B2\": \"As a Value Engineering Intern at Celonis, you used LLMs for semantic understanding of decision trees. How did this experience contribute to your understanding of data processing and analysis?\",\n",
      "    \"B3\": \"In your role as a Data Science Intern at Shelflife, you were tasked with building a markdowns optimizer using LLMs and causal inference techniques. Can you walk me through how you designed and implemented this optimizer?\",\n",
      "    \"B4\": \"As a Head Teaching Assistant at University of Pennsylvania, you developed and taught material on building and testing LLM-based chatbots. How did you ensure the material was effectively communicated to the students?\",\n",
      "    \"B5\": \"Can you discuss a time during your internship at Fellows Fund as an Investment Associate where you had to conduct due diligence on AI startup investments and how you evaluated the market potential of those investments?\",\n",
      "    \"T1\": \"Can you explain your experience in building a RESTful API using Python, Java, or Go, and how you ensured its scalability and robustness?\",\n",
      "    \"T2\": \"Have you worked with containerization technologies like Kubernetes and Docker in any of your projects? If so, can you describe the role these technologies played and the challenges you faced?\",\n",
      "    \"T3\": \"How comfortable are you with writing and tuning SQL queries, and can you provide an example of a complex query you've worked on in the past?\",\n",
      "    \"T4\": \"Have you had hands-on experience with big data processing platforms like Kafka, Spark, Iceberg, or Trino? If yes, could you share a specific project where you utilized these technologies?\",\n",
      "    \"T5\": \"Given your experience with monitoring and alerting systems, can you discuss a situation where you had to develop monitoring solutions for applications or systems integrations, and how you ensured their effectiveness in detecting issues proactively?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "questions_raw = generate_questions(attributes_raw, role, missing_info)\n",
    "print(questions_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "742aa168-800a-48fb-a76e-e9b2395e5679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B1': 'Can you describe a challenging project you worked on as a Machine Learning Engineer at Avary and how you approached solving it?', 'B2': 'As a Value Engineering Intern at Celonis, you used LLMs for semantic understanding of decision trees. How did this experience contribute to your understanding of data processing and analysis?', 'B3': 'In your role as a Data Science Intern at Shelflife, you were tasked with building a markdowns optimizer using LLMs and causal inference techniques. Can you walk me through how you designed and implemented this optimizer?', 'B4': 'As a Head Teaching Assistant at University of Pennsylvania, you developed and taught material on building and testing LLM-based chatbots. How did you ensure the material was effectively communicated to the students?', 'B5': 'Can you discuss a time during your internship at Fellows Fund as an Investment Associate where you had to conduct due diligence on AI startup investments and how you evaluated the market potential of those investments?', 'T1': 'Can you explain your experience in building a RESTful API using Python, Java, or Go, and how you ensured its scalability and robustness?', 'T2': 'Have you worked with containerization technologies like Kubernetes and Docker in any of your projects? If so, can you describe the role these technologies played and the challenges you faced?', 'T3': \"How comfortable are you with writing and tuning SQL queries, and can you provide an example of a complex query you've worked on in the past?\", 'T4': 'Have you had hands-on experience with big data processing platforms like Kafka, Spark, Iceberg, or Trino? If yes, could you share a specific project where you utilized these technologies?', 'T5': 'Given your experience with monitoring and alerting systems, can you discuss a situation where you had to develop monitoring solutions for applications or systems integrations, and how you ensured their effectiveness in detecting issues proactively?'}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "questions = ast.literal_eval(questions_raw)\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8554ed17-4b03-41fc-a860-7f188d03db49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['B1', 'B2', 'B3', 'B4', 'B5', 'T1', 'T2', 'T3', 'T4', 'T5'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a9539fd3-45a9-4692-8953-f688e96559f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interviewee_agent(attributes, role, question, history=[]):\n",
    "  system_prompt = f\"\"\"\n",
    "  You are interviewing for the following role:\\n\\n{role}.\n",
    "  \\n\\nYour resume is as follows:\\n\\n{attributes}.\n",
    "  \\n\\n Here is the history of the interview conversation up until now:\\n\\n{history}\n",
    "  You aren't a perfect candidate, your answers to questions vary from vague to irrelevant to tangential to complete. Remember to maintain a conversational tone.\n",
    "  \"\"\"\n",
    "\n",
    "  client = openai.OpenAI()\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages= [\n",
    "          {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "          {\"role\" : \"user\", \"content\" : question}\n",
    "      ],\n",
    "      temperature=0.9,\n",
    "      max_tokens=2048,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "  )\n",
    "  time.sleep(1)\n",
    "\n",
    "  history.append(question)\n",
    "\n",
    "  return history, response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c8903cb6-3e3f-43c5-a7eb-4b3f85f5b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_answer_style(role, answer, history=[]):\n",
    "  system_prompt = f\"\"\"\n",
    "  You are a job interviewer for the following role:\\n\\n{role}.\n",
    "  \\n\\n Here is the history of the interview conversation up until now:\\n\\n{history}\n",
    "  \\n\\n Provided is the interviewee's answer to your question. Classify their answer with one of the following labels:\n",
    "  \\n complete\n",
    "  \\n brief\n",
    "  \\n abstract\n",
    "  \\n irrelevant\n",
    "  \\n incomplete\n",
    "  \\n rambling\n",
    "  \\n vague\n",
    "  \\n tangential\n",
    "  \\n contradictory\n",
    "  \\n defensive\n",
    "  \"\"\"\n",
    "\n",
    "  client = openai.OpenAI()\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages= [\n",
    "          {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "          {\"role\" : \"user\", \"content\" : answer}\n",
    "      ],\n",
    "      temperature=0.7,\n",
    "      max_tokens=256,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "  )\n",
    "  time.sleep(1)\n",
    "\n",
    "  return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6586b474-8765-449b-aa02-ab7abcd8fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "be5ade86-0a64-47b9-8637-bdfe2207657d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely! At Shelflife, the markdowns optimizer project was a fascinating challenge. To begin with, I utilized Large Language Models (LLMs) to analyze customer behavior patterns and historical sales data. By leveraging these models, I could identify trends and correlations that helped in understanding how different factors influenced customer purchase decisions.\n",
      "\n",
      "Next, I incorporated causal inference techniques to determine the impact of various marketing strategies and pricing changes on sales and customer behavior. This involved conducting A/B tests and using statistical methods to isolate the causal effect of each factor.\n",
      "\n",
      "In terms of implementation, I built a custom algorithm that combined the insights from the LLM analysis and causal inference results to predict the optimal markdown strategy for different products and customer segments. This algorithm continuously learned from incoming data to adjust and refine the markdown recommendations over time.\n",
      "\n",
      "Overall, the project involved a blend of cutting-edge technology, statistical analysis, and machine learning to create a personalized and effective markdown optimization tool for Shelflife.\n"
     ]
    }
   ],
   "source": [
    "history, answer = interviewee_agent(attributes, role, questions['B3'], history)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2e9aea6a-a6bb-4af7-acb5-d7e9cdd9b509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "style = classify_answer_style(role, answer, history)\n",
    "print(style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e47d57fd-0946-4d2f-944d-6e9f8dfc1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interviewer_agent(questions, style, role, history=[]):\n",
    "  system_prompt = f\"\"\"\n",
    "  You are a job interviewer for the following role:\\n\\n{role}.\n",
    "  \\n\\n Here is the history of the interview conversation up until now:\\n\\n{history}\n",
    "  \\n\\n Provided the next answer of the interviewee, follow-up on the previous question (try to dig deeper), or ask a new question from the following question bank:\\n\\n{questions}\n",
    "  \"\"\"\n",
    "\n",
    "  client = openai.OpenAI()\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages= [\n",
    "          {\"role\" : \"system\", \"content\" : system_prompt},\n",
    "          {\"role\" : \"user\", \"content\" : answer}\n",
    "      ],\n",
    "      temperature=0.9,\n",
    "      max_tokens=2048,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "  )\n",
    "  time.sleep(1)\n",
    "\n",
    "  history.append(answer)\n",
    "\n",
    "  return history, response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e05257c4-68c7-4725-a05a-8b9c2af5be9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's truly impressive how you integrated LLMs and causal inference techniques to develop a personalized markdown optimization tool at Shelflife. Could you elaborate on how you managed the continuous learning aspect of the algorithm? Specifically, how did you handle the incoming data to ensure that the markdown recommendations were continuously adjusted and refined over time?\n"
     ]
    }
   ],
   "source": [
    "history, new_question = interviewer_agent(questions, style, role, history)\n",
    "print(new_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ce352da4-e83c-449e-a597-a3bd557d5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_interview(questions, text, role, n=3):\n",
    "    # attributes_raw = generate_candidate_attributes(text)\n",
    "    # missing_info = generate_missing_information(attributes_raw, role)\n",
    "    # questions_raw = generate_questions(attributes_raw, role, missing_info)\n",
    "    # questions = ast.literal_eval(questions_raw)\n",
    "    # print(questions)\n",
    "\n",
    "    question = questions['T1']\n",
    "    for _ in range(n):\n",
    "        print(\"====== INTERVIEWER ======\")\n",
    "        print(question)\n",
    "        history, answer = interviewee_agent(attributes, role, question)\n",
    "        print(\"====== YOU ======\")\n",
    "        print(answer)\n",
    "        history, question = interviewer_agent(questions, style, role, history)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bd1a3889-867e-4a43-8e8b-87d5e606dc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== INTERVIEWER ======\n",
      "Can you explain your experience in building a RESTful API using Python, Java, or Go, and how you ensured its scalability and robustness?\n",
      "====== YOU ======\n",
      "Absolutely! While I haven't had direct experience building a RESTful API in a professional setting using Python, Java, or Go, I have worked on projects where I have interacted with APIs and understand the fundamental concepts behind RESTful architecture.\n",
      "\n",
      "In my projects, especially the Petco Creative project where we integrated OpenAI models via APIs, I gained an appreciation for API design principles, such as endpoint design, HTTP methods, status codes, and data serialization formats like JSON. \n",
      "\n",
      "To ensure scalability and robustness, in my projects, I've focused on designing clean and efficient APIs that are easy to maintain and extend. I've paid attention to error handling, input validation, and documentation to enhance the usability of the API. Additionally, I have utilized tools like Postman for testing and monitoring API endpoints to ensure they function as expected.\n",
      "\n",
      "While I haven't yet had the opportunity to dive deep into the nitty-gritty of building RESTful APIs from scratch, I'm eager to expand my skills in this area and learn more about optimizing for scalability and robustness in a production environment.\n",
      "====== INTERVIEWER ======\n",
      "That sounds like a really interesting and challenging project! It's impressive how you combined Large Language Models with causal inference techniques to create a personalized markdown optimization tool.\n",
      "\n",
      "Could you elaborate on how you evaluated the effectiveness of the markdown recommendations generated by your algorithm? Did you have any specific metrics or validation processes in place to ensure that the recommendations were indeed improving sales and customer behavior?\n",
      "====== YOU ======\n",
      "Thank you for your interest in the project! Evaluating the effectiveness of the markdown recommendations was a crucial aspect of the implementation process. To measure the impact of the recommendations on sales and customer behavior, we established specific metrics and validation processes.\n",
      "\n",
      "One of the key metrics we used was the conversion rate, which helped us track how many customers made a purchase after receiving a markdown recommendation. By analyzing this metric over time, we could assess the direct impact of the recommendations on actual sales.\n",
      "\n",
      "Additionally, we implemented A/B testing to compare the performance of products with and without the recommended markdowns. This allowed us to isolate the effect of our algorithm on customer behavior and sales outcomes. By conducting rigorous statistical analysis on the A/B test results, we could confidently attribute any improvements to our algorithm.\n",
      "\n",
      "Moreover, we continuously monitored and analyzed customer feedback and engagement data to gather qualitative insights into the effectiveness of the markdown recommendations. Understanding how customers responded to the recommendations helped us fine-tune the algorithm and improve its performance over time.\n",
      "\n",
      "Overall, by combining quantitative metrics like conversion rates with qualitative feedback and A/B testing, we were able to validate the impact of the markdown recommendations on sales and customer behavior, ensuring that our algorithm was indeed driving positive outcomes.\n",
      "====== INTERVIEWER ======\n",
      "That's truly impressive how you leveraged Large Language Models and causal inference techniques to create a personalized markdown optimization tool at Shelflife. It's evident that your approach was very comprehensive and innovative.\n",
      "\n",
      "Could you share more details about how you fine-tuned and optimized the custom algorithm you developed for predicting the optimal markdown strategy? Additionally, how did you ensure that the algorithm continuously learned from incoming data to improve its recommendations over time?\n",
      "====== YOU ======\n",
      "Thank you for your kind words! Fine-tuning and optimizing the custom algorithm for predicting the optimal markdown strategy was a crucial part of the project. \n",
      "\n",
      "To begin with, after developing the initial algorithm that combined insights from LLM analysis and causal inference, I conducted extensive testing and validation to evaluate its performance against historical data and simulated scenarios. This process helped identify areas for improvement and optimization.\n",
      "\n",
      "One key aspect of fine-tuning the algorithm was to iteratively update and refine the model parameters based on the latest data inputs. By continuously monitoring the algorithm's predictions against actual outcomes, I could adjust the weights and biases to enhance its accuracy and effectiveness in recommending markdown strategies.\n",
      "\n",
      "In terms of continuous learning, I implemented feedback loops within the algorithm that allowed it to adapt and evolve based on new data patterns and trends. This involved setting up mechanisms to capture real-time feedback on the success of the markdown recommendations and incorporating this feedback to adjust the algorithm's decision-making process.\n",
      "\n",
      "Overall, the iterative process of testing, refining, and updating the custom algorithm, coupled with mechanisms for continuous learning and adaptation, was essential in ensuring that the markdown optimization tool remained dynamic and responsive to changing market conditions and customer behaviors.\n"
     ]
    }
   ],
   "source": [
    "history = simulate_interview(questions, text, role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a009b-1193-4b7d-98d5-7cf2d4becaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step: create an \"aspect\" surrounding each generated question\n",
    "# visualize those spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d30ee-85bb-40ef-ab2a-e4a2cf7d371b",
   "metadata": {},
   "source": [
    "The primary goal of time series analysis on sales data is to identify patterns and trends within historical sales figures to accurately predict future sales, allowing businesses to optimize inventory management, marketing strategies, and resource allocation based on anticipated demand fluctuations and seasonality.\n",
    "\n",
    "ARIMA models are used when a metric is recorded at regular intervals, such as daily, weekly, or monthly. ARIMA models assume that the future will be similar to the past. BUT this can make them inaccurate in certain market conditions, like changes in the economy\n",
    "\n",
    "A \"Holt-Winters time series\" refers to a forecasting method used in time series analysis that is particularly effective for data exhibiting both trend and seasonality. It models a time series by considering the \"level\" (current average value), \"trend\" (rate of change), and \"seasonality\" (repeating pattern). Ideal for forecasting data with clear seasonal patterns like monthly sales figures, quarterly earnings, or weather data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
